{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d581218e",
   "metadata": {},
   "source": [
    "# How good eval infra works\n",
    "\n",
    "An introduction to all things Braintrust via a speed-run through building evals for a customer support bot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f891b57",
   "metadata": {},
   "source": [
    "In this demo, we aim to enhance a city's customer support application by developing an AI workflow to streamline the request process and ensure it is routed to the correct department.\n",
    "\n",
    "This is what their current customer support app looks like:\n",
    "\n",
    "<img src=\"./data/city-of-encinitas-customer-support.gif\" height=\"300\"/>\n",
    "\n",
    "Instead of requiring citizens to know exactly where their requests should be routed, jump through all these hoops, and dismiss one pop-up after another, we hypothesize a simple UI where the user can describe their issue and an AI pipeline that will take that description, route the request to the appropraite contact, prompt the UI for any required information, and provide an answer or informational response if warranted.\n",
    "\n",
    "Let's start by importing the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from textwrap import dedent\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "import anthropic as ac\n",
    "import braintrust as bt\n",
    "import openai as oai\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from braintrust import wrap_anthropic, wrap_openai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, BeforeValidator, Field\n",
    "from thefuzz import process as fuzzy_process\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a7ed5",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Once you're signed up on [Braintrust](https://www.braintrust.dev/) and have set the appropriate API keys in your `.env` file, you're ready to go. For this particular demo, you'll need the following API keys:\n",
    "\n",
    "- `BRAINTRUST_API_KEY`\n",
    "- `OPENAI_API_KEY`\n",
    "- `ANTHROPIC_API_KEY`\n",
    "\n",
    "With that in place, we can create our [Braintrust project](https://www.braintrust.dev/docs/guides/projects) using `braintrust.projects.create()` (this method will create or return the project if it already exists).\n",
    "\n",
    "We also define Anthropic and OpenAI clients like usual, as well as a \"wrapped\" version of each client. These \"wrapped\" versions automatically capture usage data (e.g., prompt tokens, etc) in Braintrust when used within the context of a logger or experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BT_PROJECT_NAME = \"wayde-ai-evals-course-2025\"\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "bt_project = bt.projects.create(name=BT_PROJECT_NAME)\n",
    "\n",
    "ac_client = ac.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "oai_client = oai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "wrapped_ac_client = wrap_anthropic(ac_client)\n",
    "wrapped_oai_client = wrap_openai(oai_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911eb962",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba6b01",
   "metadata": {},
   "source": [
    "\"Every error analysis starts with _traces_: the full sequence of inputs, outputs, and actions taken by the pipeline for a given input\"\n",
    "\n",
    "The recommendation is to start with ~ 100 traces of diverse user intents, with preference given to real-world data where possible. In this case, we don't have access to such data and so we'll follow the AIE methodology for creating synthetic data. We'll braintrustify this workflow a bit along the way :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d233210",
   "metadata": {},
   "source": [
    "### Step 1: Define dimensions\n",
    "\n",
    "\"First, before prompting anything, we define key dimensions of the query space... [to] help us systematically vary different aspects of a userâ€™s request\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ca292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionTuple(BaseModel):\n",
    "    inquiry_type: str = Field(\n",
    "        description=\"What kind of inquiry are they making (e.g. informational_ask, complaint,request_for_action_or_service)\"\n",
    "    )\n",
    "    query_style_and_detail: str = Field(\n",
    "        description=\"The style and detail of the query (e.g. short_keywords_minimal_detail, concise_moderate_detail, verbose_detailed_request)\"\n",
    "    )\n",
    "    customer_persona: str = Field(\n",
    "        description=\"Who is making the request (e.g. business_owner, citizen)\",\n",
    "    )\n",
    "    customer_age: str = Field(\n",
    "        description=\"The age of the person making the request (e.g. senior_over_65, youth_under_18, adult)\",\n",
    "    )\n",
    "\n",
    "\n",
    "class DimensionTuples(BaseModel):\n",
    "    tuples: list[DimensionTuple]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af157a53",
   "metadata": {},
   "source": [
    "### Step 2: Define dimension values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f57b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUPLES_GEN_PROMPT = \"\"\"\\\n",
    "I am designing a customer support chatbot for the city of Encinitas and I want to test it against a diverse\n",
    "range of inquiries citizens might submit. I have provided you with several dimensions and that constitute the parts of\n",
    "such a queries along with a list of possible values for each dimension.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Generate {{{num_tuples_to_generate}}} unique combinations of dimension values for based on the dimensions provided below. \n",
    "- Each combination should represent a different user scenario. \n",
    "- Ensure balanced coverage across all dimensions - don't over-represent any particular value or combination.\n",
    "- Vary the query styles naturally.\n",
    "- Attempt to make the dimension value combinations as realistic as possible.\n",
    "- Never generate a tuple where the customer_persona is a business_owner and the customer_age is youth_under_18.\n",
    "\n",
    "## Dimensions\n",
    "\n",
    "inquiry_type:\n",
    "- informational_ask\n",
    "- complaint\n",
    "- request_for_action_or_service\n",
    "\n",
    "query_style_and_detail:\n",
    "- concise_moderate_detail: [includes some details relevant to the `inquiry_topic`, e.g., location, names, etc.]\n",
    "- verbose_detailed_request: [includes specific details relevant to the `inquiry_topic`, e.g., location, names, etc.]\n",
    "- short_keywords_minimal_details\n",
    "\n",
    "customer_persona: Who is making the request\n",
    "- business_owner\n",
    "- citizen\n",
    "\n",
    "customer_age: The age of the person making the request\n",
    "- senior_over_65\n",
    "- youth_under_18\n",
    "- adult\n",
    "\n",
    "Generate {{{num_tuples_to_generate}}} unique dimension tuples following these patterns. Remember to maintain balanced diversity across all dimensions.\"\"\"\n",
    "\n",
    "# print(TUPLES_GEN_PROMPT.replace(\"{{{num_tuples_to_generate}}}\", \"10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf32d0d",
   "metadata": {},
   "source": [
    "Create a versioned prompt and save it to Braintrust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a340f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n",
    "try:\n",
    "    tuples_gen_prompt.build(num_tuples_to_generate=20)\n",
    "except Exception as e:\n",
    "    bt_tuples_gen_prompt = bt_project.prompts.create(\n",
    "        name=\"DimensionTuplesGenPrompt\",\n",
    "        slug=\"dimension-tuples-gen-prompt\",\n",
    "        description=\"Prompt for generating dimension tuples\",\n",
    "        model=\"claude-4-sonnet-20250514\",\n",
    "        messages=[{\"role\": \"user\", \"content\": TUPLES_GEN_PROMPT}],\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "\n",
    "    bt_project.publish()\n",
    "    tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc0119",
   "metadata": {},
   "source": [
    "With this in place, we can engage our domain experts in the prompt-building process via our [playgrounds](https://www.braintrust.dev/docs/guides/playground) and use our eval-specific AI assistant, [Loop](https://www.braintrust.dev/docs/guides/loop).\n",
    "\n",
    "We'll prompt Loop to improve our \"prompt\" like this:\n",
    "\n",
    "> \"Help me improve this prompt to capture all the different dimensions a customer support inquiry may have for the city of Encinitas.\n",
    ">\n",
    "> The dimensions and their values should represent realistic aspects of a customer support request they may get\"\n",
    "\n",
    "We can then get our updated prompt, make changes to the structured output definition, and generate some data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac227e",
   "metadata": {},
   "source": [
    "Fetch our improved prompt and update our Pydantic model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8da9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _p = tuples_gen_prompt.build(num_tuples_to_generate=20)\n",
    "# print(_p[\"messages\"][0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionTuple(BaseModel):\n",
    "    inquiry_type: str = Field(\n",
    "        description=\"What kind of inquiry are they making (e.g. informational_ask, complaint, request_for_action_or_service, report_or_notification, permit_or_license_inquiry, payment_or_billing_question)\"\n",
    "    )\n",
    "    query_style_and_detail: str = Field(\n",
    "        description=\"The style and detail of the query (e.g. concise_moderate_detail, verbose_detailed_request, short_keywords_minimal_details)\"\n",
    "    )\n",
    "    customer_persona: str = Field(\n",
    "        description=\"Who is making the request (e.g. business_owner, citizen, property_owner, visitor_tourist, contractor_developer)\",\n",
    "    )\n",
    "    customer_age: str = Field(\n",
    "        description=\"The age of the person making the request (e.g. senior_over_65, youth_under_18, adult)\",\n",
    "    )\n",
    "    urgency_level: str = Field(\n",
    "        description=\"How urgent the customer perceives their issue to be (e.g. low_routine_inquiry, medium_timely_response_needed, high_urgent_immediate_attention)\"\n",
    "    )\n",
    "    communication_tone: str = Field(\n",
    "        description=\"The emotional tone of the inquiry (e.g. neutral_professional, frustrated_annoyed, polite_respectful, demanding_aggressive, confused_seeking_clarification)\"\n",
    "    )\n",
    "    time_sensitivity: str = Field(\n",
    "        description=\"When the issue occurred or needs resolution (e.g. ongoing_chronic_issue, recent_within_week, immediate_happening_now, future_planning_ahead)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class DimensionTuples(BaseModel):\n",
    "    tuples: list[DimensionTuple]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ee383",
   "metadata": {},
   "source": [
    "### Step 3: Use an LLM to generate N unique combinations of these dimension values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_data_dimension_tuples(num_tuples: int = 20, model: str = \"gpt-4o-mini\", model_kwargs: dict = {}):\n",
    "    \"\"\"Generate a list of dimension tuples based on the provided prompt.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    prompt = tuples_gen_prompt.build(num_tuples_to_generate=num_tuples)\n",
    "\n",
    "    rsp = oai_client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=prompt[\"messages\"],\n",
    "        response_format=DimensionTuples,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "\n",
    "    tuples_list: DimensionTuples = rsp.choices[0].message.parsed  # type: ignore\n",
    "\n",
    "    unique_tuples = []\n",
    "    seen = set()\n",
    "\n",
    "    for tup in tuples_list.tuples:\n",
    "        tuple_str = tup.model_dump_json()\n",
    "        if tuple_str in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(tuple_str)\n",
    "        unique_tuples.append(tup)\n",
    "\n",
    "    bt_experiment = bt.init(project=BT_PROJECT_NAME, experiment=f\"synth_tuples_it_{timestamp}\")\n",
    "    for uniq_tup in unique_tuples:\n",
    "        with bt_experiment.start_span(name=\"generate_dimension_tuples\") as span:\n",
    "            span.log(input=prompt[\"messages\"], output=uniq_tup, metadata=dict(model=model, model_kwargs=model_kwargs))\n",
    "\n",
    "    summary = bt_experiment.summarize(summarize_scores=False)\n",
    "    return summary, rsp.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_summary, dim_tuples = generate_synth_data_dimension_tuples(20)\n",
    "\n",
    "print(exp_summary)\n",
    "print(dim_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91442ec6",
   "metadata": {},
   "source": [
    "### Step 4: Remove invalid dimension tuples (human/SME review)\n",
    "\n",
    "We'll do this in the Braintrust UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b66a28",
   "metadata": {},
   "source": [
    "### Step 5: Demonstrate an approach to building + 20 queries with the help of a SME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f521eedc",
   "metadata": {},
   "source": [
    "Working with an SME and ChatGPT, we were able to capture all of the contacts, customer support requests get routed, and a description of the types of inquiries each gets routed their way. We even curated 5 example support requests for each of these contacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_support_areas = json.load(open(\"./data/dept_support_areas.json\"))\n",
    "\n",
    "triage_targets = list(set([route[\"slug\"] for route in dept_support_areas]))\n",
    "\n",
    "print(len(triage_targets))\n",
    "triage_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, triage_point in enumerate(dept_support_areas):\n",
    "    if idx >= 2:\n",
    "        break\n",
    "    print(f\"{triage_point['name']} ({triage_point['slug']})\")\n",
    "    print(\"- \" + \"\\n- \".join(triage_point[\"support_areas\"][:5]))\n",
    "    print(\"-> \" + \"\\n-> \".join(triage_point[\"examples\"][:5]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b334a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_examples = {}\n",
    "for triage_contact in dept_support_areas:\n",
    "    triage_target = triage_contact[\"slug\"]\n",
    "    if triage_target not in triage_examples:\n",
    "        triage_examples[triage_target] = {\"name\": triage_contact[\"name\"], \"support_areas\": triage_contact[\"support_areas\"], \"examples\": []}\n",
    "    triage_examples[triage_target][\"examples\"].extend(triage_contact[\"examples\"])\n",
    "\n",
    "print(f\"Total triage targets: {len(triage_examples)}\")\n",
    "print(f\"Total examples: {sum(len(data['examples']) for data in triage_examples.values())}\")\n",
    "print(f\"First 5 examples for '{list(triage_examples.keys())[0]}': {triage_examples[list(triage_examples.keys())[0]]['examples'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16b0eb",
   "metadata": {},
   "source": [
    "### Step 6. Scale up 100 or more tuples + queries using an LLM\n",
    "\n",
    "We can use the \"BTQL Sandbox\" to help us construct a query to get the \"good\" dimension tuples from our annotation exercise, and then use that query to get those records to build some synthetic queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1645afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_dimension_tuples():\n",
    "    cursor = None\n",
    "    while True:\n",
    "        response = requests.post(\n",
    "            \"https://staging-api.braintrust.dev/btql\",\n",
    "            json={\n",
    "                \"query\": dedent(\"\"\"\n",
    "                        select: output\n",
    "                        from: experiment('36b63064-7f4e-46a4-9673-5533fa327dc5')\n",
    "                        filter: scores.\"is_good\" = 1\n",
    "                \"\"\")\n",
    "                + (f\" | cursor: '{cursor}'\" if cursor else \"\"),\n",
    "                \"use_brainstore\": True,\n",
    "                \"brainstore_realtime\": True,  # Include the latest realtime data, but a bit slower.\n",
    "            },\n",
    "            headers={\"Authorization\": \"Bearer \" + os.environ[\"BRAINTRUST_API_KEY\"]},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        data = response_json.get(\"data\", [])\n",
    "        cursor = response_json.get(\"cursor\")\n",
    "\n",
    "        return [row[\"output\"] for row in data]\n",
    "\n",
    "\n",
    "valid_dim_tuples = get_valid_dimension_tuples()\n",
    "\n",
    "# print(len(valid_dim_tuples))\n",
    "# valid_dim_tuples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bfc2bb",
   "metadata": {},
   "source": [
    "Create a versioned prompt and save it to Braintrust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTH_DATA_GEN_PROMPT = \"\"\"\\\n",
    "I am designing a customer support chatbot for the city of Encinitas and I want to test it against a diverse\n",
    "range of realistic inquiries citizens that would appropriately be routed to this contact:\n",
    "\n",
    "Contact: {{{contact_name}}}\n",
    "Support Areas: {{{support_areas}}}\n",
    "\n",
    "## Objective\n",
    "\n",
    "Produce {{{num_queries_to_generate}}} additional natural language customer support requests using a sample of actual customer support requests \n",
    "below, but augmented to have one of the characteristics listed below:\n",
    "\n",
    "==== Inquiry Characteristics =====\n",
    "{{{dimension_tuple_json}}}\n",
    "\n",
    "===== Example Inquiries =====\n",
    "{{{example_inquiries}}}\n",
    "\n",
    "## Instructions\n",
    "To produce each inquiry, follow these steps:\n",
    "1. Choose a random example from the list of example inquiries above.\n",
    "2. Choose a random record from the list of inquiry characteristics above.\n",
    "3. Augment the example inquiry to have the chosen characteristic of that record.\n",
    "4. Return the augmented inquiry.\n",
    "\n",
    "The queries should:\n",
    "1. Sound like real users asking for assistance\n",
    "2. Naturally incorporate all the dimension values\n",
    "3. Vary in style and detail level\n",
    "4. Be realistic and practical\n",
    "5. Change any named entities (locations, addresses, street names, person names, etc...) to diversify the content\n",
    "5. Include natural variations in typing style, such as:\n",
    "   - Some queries in all lowercase\n",
    "   - Some with random capitalization\n",
    "   - Some with common typos\n",
    "   - Some with missing punctuation\n",
    "   - Some with extra spaces or missing spaces\n",
    "   - Some with emojis or text speak\n",
    "\n",
    "Here are examples of realistic query variations for a request to get a pothole fixed from \n",
    "an adult, business_owner, concise_moderate_detail:\n",
    "\n",
    "Proper formatting:\n",
    "- \"There is a huge pothole on the corner of 123 Main St. It's been there for weeks affecting customers trying to park nearby\"\n",
    "- \"Can someone please fix the pothole on 123 Main St.\"\n",
    "\n",
    "All lowercase:\n",
    "- \"need someone to fix the pothole on 123 main st.\"\n",
    "- \"can a crew come out and fix the pothole on the corner of 123 main st. and grand ave.\"\n",
    "\n",
    "Random caps:\n",
    "- \"NEED someone to fix the pothole on 123 main st. ASAP\"\n",
    "- \"can a crew come out and fix the pothole on the corner of 123 main st. and grand ave??? It needs to happen NOW! Like today!\"\n",
    "\n",
    "Common typos:\n",
    "- \"need someone to fx the pothol on 123 main st. asap pleze!!!\"\n",
    "- \"Can a crew come out and fx the pothole on the corner of 123 main st. & grand ave??? thx much!\"\n",
    "\n",
    "Missing punctuation:\n",
    "- \"need someone to fx the pothole on 123 main st asap plz\"\n",
    "- \"Can a crew come out and fix the pothole on the corner of 123 main st & grand ave ... thx much\"\n",
    "\n",
    "With emojis/text speak:\n",
    "- \"the pothole needs to be fixed now on 123 main st. and grand ave! ðŸ¥—\"\n",
    "- \"pls help get the pothole on 123 main st. & grand ave fixed thx\"\n",
    "\n",
    "Generate {{{num_queries_to_generate}}} unique queries,varying the text style naturally.\"\"\"\n",
    "\n",
    "\n",
    "# print(\n",
    "#     (\n",
    "#         SYNTH_DATA_GEN_PROMPT.replace(\"{{{num_queries_to_generate}}}\", \"4\")\n",
    "#         .replace(\"{{{dimension_tuple_json}}}\", json.dumps(valid_dim_tuples[:4], indent=2))\n",
    "#         .replace(\"{{{example_inquiries}}}\", \"- \" + \"\\n- \".join(triage_examples[\"public_works\"][\"examples\"][:5]))\n",
    "#         .replace(\"{{{contact_name}}}\", triage_examples[\"public_works\"][\"name\"])\n",
    "#         .replace(\"{{{support_areas}}}\", \", \".join(triage_examples[\"public_works\"][\"support_areas\"]))\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123dc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_query_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"synth-query-gen-prompt\")\n",
    "try:\n",
    "    synth_query_gen_prompt.prompt\n",
    "except Exception as e:\n",
    "    bt_syth_query_gen_prompt = bt_project.prompts.create(\n",
    "        name=\"SynthQueryGenPrompt\",\n",
    "        slug=\"synth-query-gen-prompt\",\n",
    "        description=\"Prompt for generating synthetic queries\",\n",
    "        model=\"claude-4-sonnet-20250514\",\n",
    "        messages=[{\"role\": \"user\", \"content\": SYNTH_DATA_GEN_PROMPT}],\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "\n",
    "    bt_project.publish()\n",
    "    synth_query_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"synth-query-gen-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37924943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _p = synth_query_gen_prompt.build(\n",
    "#     num_queries_to_generate=4,\n",
    "#     dimension_tuple_json=json.dumps(valid_dim_tuples[:4], indent=2),\n",
    "#     example_inquiries=\"- \" + \"\\n- \".join(triage_examples[\"public_works\"][\"examples\"][:5]),\n",
    "#     contact_name=triage_examples[\"public_works\"][\"name\"],\n",
    "#     support_areas=\", \".join(triage_examples[\"public_works\"][\"support_areas\"]),\n",
    "# )\n",
    "\n",
    "# _p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa2f69",
   "metadata": {},
   "source": [
    "Generate synthetic data we can later run through our customer support bot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077da744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryList(BaseModel):\n",
    "    queries: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_queries(triage_slug: str, num_queries: int = 10, model: str = \"gpt-4o-mini\", model_kwargs: dict = {}) -> dict:\n",
    "    random_dim_tuples = random.sample(valid_dim_tuples, min(num_queries, len(valid_dim_tuples)))\n",
    "\n",
    "    prompt = synth_query_gen_prompt.build(\n",
    "        num_queries_to_generate=num_queries,\n",
    "        dimension_tuple_json=json.dumps(random_dim_tuples, indent=2),\n",
    "        example_inquiries=\"- \" + \"\\n- \".join(triage_examples[triage_slug][\"examples\"][:5]),\n",
    "        contact_name=triage_examples[triage_slug][\"name\"],\n",
    "        support_areas=\", \".join(triage_examples[triage_slug][\"support_areas\"]),\n",
    "    )\n",
    "\n",
    "    rsp = oai_client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=prompt[\"messages\"],\n",
    "        response_format=QueryList,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "\n",
    "    query_list: QueryList = rsp.choices[0].message.parsed  # type: ignore\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt[\"messages\"],\n",
    "        \"triage_slug\": triage_slug,\n",
    "        \"sampled_dim_tuples\": random_dim_tuples,\n",
    "        \"handcoded_queries\": triage_examples[triage_slug][\"examples\"],\n",
    "        \"synth_queries\": query_list.queries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7432cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsp = generate_synth_queries(\"public_works\", num_queries=10)\n",
    "\n",
    "# for q in rsp[\"handcoded_queries\"]:\n",
    "#     print(q)\n",
    "# print(\"-\" * 100)\n",
    "# for q in rsp[\"synth_queries\"]:\n",
    "#     print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries_parallel(triage_targets: list[str], num_queries: int = 10, model: str = \"gpt-4o-mini\", model_kwargs: dict = {}):\n",
    "    \"\"\"Generate queries in parallel for all dimension tuples.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "    print(f\"Generating {num_queries} queries each for {len(triage_targets)} triage targets...\")\n",
    "    # Run in parallel\n",
    "    worker = partial(generate_synth_queries, num_queries=num_queries, model=model, model_kwargs=model_kwargs)\n",
    "    responses = list(ThreadPoolExecutor(max_workers=MAX_WORKERS).map(worker, triage_targets))\n",
    "\n",
    "    # Add query items\n",
    "    all_queries = []\n",
    "    for response in responses:\n",
    "        prompt = response[\"prompt\"]\n",
    "        triage_slug = response[\"triage_slug\"]\n",
    "\n",
    "        queries = [{\"prompt\": prompt, \"triage_slug\": triage_slug, \"query\": q, \"query_source\": \"synth\"} for q in response[\"synth_queries\"]]\n",
    "        queries.extend(\n",
    "            [{\"prompt\": prompt, \"triage_slug\": triage_slug, \"query\": q, \"query_source\": \"handcoded\"} for q in response[\"handcoded_queries\"]]\n",
    "        )\n",
    "\n",
    "        all_queries.extend(queries)\n",
    "\n",
    "    # Add to experiment\n",
    "    bt_experiment = bt.init(project=BT_PROJECT_NAME, experiment=f\"add_queries_it_{timestamp}\")\n",
    "    query_id = 1\n",
    "\n",
    "    for query_item in all_queries:\n",
    "        qid = f\"{timestamp}_{query_id:03d}\"\n",
    "        query_id += 1\n",
    "\n",
    "        with bt_experiment.start_span(name=\"add_query\") as span:\n",
    "            span.log(\n",
    "                input=query_item[\"prompt\"],\n",
    "                output=query_item[\"query\"],\n",
    "                metadata={\n",
    "                    \"id\": qid,\n",
    "                    \"triage_slug\": query_item[\"triage_slug\"],\n",
    "                    \"query_source\": query_item[\"query_source\"],\n",
    "                    \"model\": model,\n",
    "                    \"model_kwargs\": model_kwargs,\n",
    "                },\n",
    "            )\n",
    "\n",
    "    summary = bt_experiment.summarize(summarize_scores=False)\n",
    "    return summary, queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary, queries = generate_queries_parallel(triage_targets, num_queries=10, model=\"gpt-4o-mini\")\n",
    "# summary, queries = generate_queries_parallel(triage_targets[:2], num_queries=10, model=\"gpt-4o-mini\")\n",
    "\n",
    "print(len(queries))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981281b",
   "metadata": {},
   "source": [
    "### Step 7. Remove invalid queries (human/SME review)\n",
    "\n",
    "We'll do this in the Braintrust UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bde21",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Let's use our \"good\" synthetic and hand-coded queries to build a real-world customer support bot with two main components:\n",
    "\n",
    "1. A web search retrieval task to gather context for answering and routing requests.\n",
    "2. A retrieval synthesis task that takes the output from the retrievals to determine where to route support, what information is needed to resolve the request, and to generate some form of response for the user.\n",
    "\n",
    "To achieve this, we'll define some tasks and [log](https://www.braintrust.dev/docs/guides/logs) them to Braintrust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_logger = bt.init_logger(project=BT_PROJECT_NAME)\n",
    "\n",
    "dept_support_areas = json.load(open(\"./data/dept_support_areas.json\"))\n",
    "triage_targets = list(set([route[\"slug\"] for route in dept_support_areas]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437438e",
   "metadata": {},
   "source": [
    "Let's use our old friend, the \"BTQL Sandbox\" to build a query to get only the queries marked as good from the human review above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    cursor = None\n",
    "    while True:\n",
    "        response = requests.post(\n",
    "            \"https://staging-api.braintrust.dev/btql\",\n",
    "            json={\n",
    "                \"query\": dedent(\"\"\"\n",
    "                        select: output, metadata\n",
    "                        from: experiment('b715cf02-86f6-4471-bc10-cef617e128ec')\n",
    "                        filter: scores.\"is_good\" = 1\n",
    "                \"\"\")\n",
    "                + (f\" | cursor: '{cursor}'\" if cursor else \"\"),\n",
    "                \"use_brainstore\": True,\n",
    "                \"brainstore_realtime\": True,  # Include the latest realtime data, but a bit slower.\n",
    "            },\n",
    "            headers={\"Authorization\": \"Bearer \" + os.environ[\"BRAINTRUST_API_KEY\"]},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        data = response_json.get(\"data\", [])\n",
    "        cursor = response_json.get(\"cursor\")\n",
    "\n",
    "        return [{\"input\": row[\"output\"], \"metadata\": row[\"metadata\"]} for row in data]\n",
    "\n",
    "\n",
    "test_data = get_test_data()\n",
    "\n",
    "print(len(test_data))\n",
    "test_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b6923",
   "metadata": {},
   "source": [
    "### Retrieval\n",
    "\n",
    "The first sub-task we need is a retrieval task to gather the appropriate context for routing and responding to the customer support request.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588a79d",
   "metadata": {},
   "source": [
    "#### Prompt\n",
    "\n",
    "We will create a versioned prompt as we did above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB_SEARCH_SYSTEM_PROMPT = dedent(\"\"\"\\\n",
    "    Your name is Sunny and you are in charge of answering question about the city of {{{city}}} and routing requests to the correct departments for triage.\n",
    "    You are given access to a web search retrieval tool to use in an attempt to answer satisfy the user's inquiry.\n",
    "    \n",
    "    ## Instructions\n",
    "    - Always include any relevant links in your response! Never respond with a generic link placeholder like '(Note: The specific registration link would be on the city's website)'     \n",
    "    - If you cannot find the information you need or fulfill the request, make sure to tell the user that in the final answer\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdfee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_web_search_prompt = bt_project.prompts.create(\n",
    "    name=\"WebSearchPrompt\",\n",
    "    slug=\"web-search-prompt\",\n",
    "    description=\"Prompt for retrieving context from the web\",\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": WEB_SEARCH_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"{{{query}}}\"},\n",
    "    ],\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "bt_project.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd029242",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"web-search-prompt\")\n",
    "web_search_prompt.build(city=\"Encinitas\", query=\"What is the weather in Encinitas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6ae37",
   "metadata": {},
   "source": [
    "#### Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0e132",
   "metadata": {},
   "source": [
    "We'll use Anthropic's built-in [web search tool](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/web-search-tool) for our initial build.\n",
    "\n",
    "We'll configure it to only use this particular city's domain and also assume the user's location to be within the city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the number of searches per request\n",
    "N_SEARCHES = 1\n",
    "\n",
    "# To limit the scope of the search to specific domains\n",
    "RETRIEVAL_WEB_SEARCH_ALLOWED_DOMAINS = [\n",
    "    \"encinitasca.gov\",\n",
    "    # \"anc.apm.activecommunities.com/encinitasparksandrec\",  # P&R activity registration\n",
    "    # \"/issuu.com/encinitasca.gov/\",  # P&R activty guides\n",
    "]\n",
    "\n",
    "# To localize search results based on user's location\n",
    "USER_LOCATION = {\n",
    "    \"type\": \"approximate\",\n",
    "    \"city\": \"Encinitas\",\n",
    "    \"region\": \"California\",\n",
    "    \"country\": \"US\",\n",
    "    \"timezone\": \"America/Los_Angeles\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bt.traced()\n",
    "def ac_web_search(query: str, city: str, model=\"claude-sonnet-4-20250514\", model_kwargs={}):\n",
    "    \"\"\"Search the web for the given query.\"\"\"\n",
    "\n",
    "    prompt = web_search_prompt.build(city=city, query=query)\n",
    "\n",
    "    rsp = wrapped_ac_client.messages.create(\n",
    "        model=model,\n",
    "        system=prompt[\"messages\"].pop(0)[\"content\"],\n",
    "        messages=prompt[\"messages\"],\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"web_search_20250305\",\n",
    "                \"name\": \"web_search\",\n",
    "                \"max_uses\": N_SEARCHES,\n",
    "                \"allowed_domains\": RETRIEVAL_WEB_SEARCH_ALLOWED_DOMAINS,\n",
    "                \"user_location\": USER_LOCATION,\n",
    "            }  # type: ignore\n",
    "        ],\n",
    "        **model_kwargs,\n",
    "    )\n",
    "    return rsp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_example = test_data[0]\n",
    "# _example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with bt_logger.start_span(name=\"web_search\") as trace:\n",
    "rsp = ac_web_search(\n",
    "    _example[\"input\"],\n",
    "    \"Encinitas\",\n",
    "    model_kwargs={\"max_tokens\": 2048, \"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 1024}},\n",
    ")\n",
    "\n",
    "rsp\n",
    "# rsp.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db196e",
   "metadata": {},
   "source": [
    "#### Parse utility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da926a00",
   "metadata": {},
   "source": [
    "Let's create a utility function to parse the web search tool's response into something more digestible. This will allow us to control exactly what bits we want to pass in as context to our synthesis task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ac_web_search_response(message):\n",
    "    \"\"\"\n",
    "    Parse a web search response message to extract searches, results, citations, and final answers.\n",
    "\n",
    "    Args:\n",
    "        message: The message object from Anthropic's web search tool\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains 'searches', 'results', 'citations', and 'final_answer'\n",
    "    \"\"\"\n",
    "\n",
    "    searches = []\n",
    "    results = []\n",
    "    citations = []\n",
    "    final_answer_parts = []\n",
    "\n",
    "    # Iterate through all content blocks\n",
    "    for block in message.content:\n",
    "        # Extract search queries\n",
    "        if hasattr(block, \"type\") and block.type == \"server_tool_use\":\n",
    "            if hasattr(block, \"name\") and block.name == \"web_search\":\n",
    "                search_query = block.input.get(\"query\", \"No query found\")\n",
    "                searches.append({\"id\": block.id, \"query\": search_query, \"input\": block.input})\n",
    "\n",
    "        # Extract search results\n",
    "        elif hasattr(block, \"type\") and block.type == \"web_search_tool_result\":\n",
    "            for result_block in block.content:\n",
    "                if hasattr(result_block, \"type\") and result_block.type == \"web_search_result\":\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"title\": result_block.title,\n",
    "                            \"url\": result_block.url,\n",
    "                            \"encrypted_content\": result_block.encrypted_content,\n",
    "                            \"page_age\": getattr(result_block, \"page_age\", None),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Extract final answer text blocks (with or without citations)\n",
    "        elif hasattr(block, \"type\") and block.type == \"text\":\n",
    "            text_content = block.text\n",
    "            block_citations = getattr(block, \"citations\", None)\n",
    "\n",
    "            # Add to final answer\n",
    "            final_answer_parts.append(text_content)\n",
    "\n",
    "            # If this text block has citations, extract them\n",
    "            if block_citations:\n",
    "                for citation in block_citations:\n",
    "                    citations.append(\n",
    "                        {\"cited_text\": citation.cited_text, \"title\": citation.title, \"url\": citation.url, \"type\": citation.type}\n",
    "                    )\n",
    "\n",
    "    return {\"searches\": searches, \"results\": results, \"citations\": citations, \"final_answer\": \"\".join(final_answer_parts)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927cd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the parsing function with the existing response\n",
    "parsed = parse_ac_web_search_response(rsp)\n",
    "\n",
    "print(\"=== SEARCHES ===\")\n",
    "for i, search in enumerate(parsed[\"searches\"], 1):\n",
    "    print(f\"{i}. Query: {search['query']}\")\n",
    "    print(f\"   ID: {search['id']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== RESULTS ===\")\n",
    "for i, result in enumerate(parsed[\"results\"], 1):\n",
    "    print(f\"{i}. {result['title']}\")\n",
    "    print(f\"   URL: {result['url']}\")\n",
    "    print(f\"   Page Age: {result['page_age']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== CITATIONS ===\")\n",
    "for i, citation in enumerate(parsed[\"citations\"], 1):\n",
    "    print(f\"{i}. Cited Text: {citation['cited_text'][:100]}...\")\n",
    "    print(f\"   Title: {citation['title']}\")\n",
    "    print(f\"   URL: {citation['url']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== FINAL ANSWER ===\")\n",
    "print(parsed[\"final_answer\"])  # [:500] + \"...\" if len(parsed[\"final_answer\"]) > 500 else parsed[\"final_answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a57d8",
   "metadata": {},
   "source": [
    "#### Task (v2)\n",
    "\n",
    "After review, we only need to pass in the `final_answer` as context to formulate a proper response. We'll update our task function as such:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bt.traced()\n",
    "def ac_web_search(query: str, city: str, model=\"claude-sonnet-4-20250514\", model_kwargs={}):\n",
    "    \"\"\"Search the web for the given query.\"\"\"\n",
    "\n",
    "    prompt = web_search_prompt.build(city=city, query=query)\n",
    "\n",
    "    rsp = wrapped_ac_client.messages.create(\n",
    "        model=model,\n",
    "        system=prompt[\"messages\"].pop(0)[\"content\"],\n",
    "        messages=prompt[\"messages\"],\n",
    "        **model_kwargs,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"web_search_20250305\",\n",
    "                \"name\": \"web_search\",\n",
    "                \"max_uses\": N_SEARCHES,\n",
    "                \"allowed_domains\": RETRIEVAL_WEB_SEARCH_ALLOWED_DOMAINS,\n",
    "                \"user_location\": USER_LOCATION,\n",
    "            }  # type: ignore\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # return rsp\n",
    "    parsed = parse_ac_web_search_response(rsp)\n",
    "    return {\"citations\": parsed[\"citations\"], \"final_answer\": parsed[\"final_answer\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8025bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp = ac_web_search(\n",
    "    _example[\"input\"],\n",
    "    \"Encinitas\",\n",
    "    model_kwargs={\"max_tokens\": 2048, \"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 1024}},\n",
    ")\n",
    "\n",
    "rsp\n",
    "# rsp.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a871b5d",
   "metadata": {},
   "source": [
    "### Retrieval synthesis\n",
    "\n",
    "The second sub-task we need is a synthesis task that takes the retrieved context and attempts to provide an appropriate response, route the request to the correct contact, and finally identify any other information that would be needed to properly respond.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79215b2",
   "metadata": {},
   "source": [
    "#### Prompt\n",
    "\n",
    "We will create a versioned prompt as we have for the other tasks above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512435eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dept in dept_support_areas[:2]:\n",
    "    print(dept[\"name\"])\n",
    "    print(\"- \" + \"\\n- \".join(dept[\"support_areas\"]))\n",
    "    print(\"-> \" + \"\\n-> \".join(dept[\"examples\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba54a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_triage_route_details() -> str:\n",
    "    output = \"=\" * 10 + \"\\n\"\n",
    "    for dept in dept_support_areas:\n",
    "        output += f\"Triage Target: {dept['slug']}\\n\"\n",
    "        output += f\"Triage Name: {dept['name']}\\n\"\n",
    "        output += f\"Support Areas: {','.join(dept['support_areas'])}\"\n",
    "        output += \"\\n\" + \"=\" * 10 + \"\\n\"\n",
    "\n",
    "    return output.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(build_triage_route_details()[:550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTHESIZE_RETRIEVAL_SYSTEM_PROMPT = f\"\"\"\\\n",
    "Your name is Sunny and you are an expert in providing responses to customer support responses for the city of {{{{city}}}} based on the original user inquiry, \n",
    "triage route descriptions, and the context provided.\n",
    "\n",
    "## Instructions\n",
    "- Provide a final answer to the user inquiry ONLY if it is answerable from the \"Context\" provided below.\n",
    "- Using the user's inquiry and the \"Context\" provided below, choose the most specific triage target to route the user to based on the \"Triage Options\" defined below.\n",
    "- If provided, make sure you include any relevant links, phone numbers, emails, or other information from the \"Context\" and how the user can use them to get the information they need.\n",
    "- Use markdown formatting for the full response.\n",
    "- Always direct complaints about personnel to \"human_resources\"\n",
    "\n",
    "## Triage Options    \n",
    "{build_triage_route_details()}\n",
    "\n",
    "## Context\n",
    "{{{{context}}}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f183edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_retieval_synthesis_prompt = bt_project.prompts.create(\n",
    "    name=\"WebSearchRetrievalSynthesis\",\n",
    "    slug=\"web-search-retrieval-synthesis\",\n",
    "    description=\"Prompt for synthesizing the retrieval results into a final answer\",\n",
    "    model=\"claude-4-sonnet-20250514\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYNTHESIZE_RETRIEVAL_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"User Inquiry: {{{user_inquiry}}}\"},\n",
    "    ],\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "bt_project.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f590a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_synth_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"web-search-retrieval-synthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f02770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _p = retrieval_synth_prompt.build(city=\"Encinitas\", user_inquiry=_example[\"input\"], context=rsp)\n",
    "# print(_p[\"messages\"][0][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac94a1",
   "metadata": {},
   "source": [
    "#### Structured output definition\n",
    "\n",
    "We structure the output as a Pydantic class so we can better get at and evaluate the different aspects of our AI pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerSupportResponse(BaseModel):\n",
    "    \"\"\"The response from the customer support agent.\"\"\"\n",
    "\n",
    "    def convert_str_to_triage_target(v: str) -> str:  # type: ignore\n",
    "        \"\"\"Ensure entity type is a valid enum.\"\"\"\n",
    "        if v in triage_targets:\n",
    "            return v\n",
    "        else:\n",
    "            try:\n",
    "                match, score = fuzzy_process.extractOne(v.upper(), [s.upper() for s in triage_targets])  # type: ignore\n",
    "                return match if score >= 80 else \"General\"\n",
    "            except ValueError:\n",
    "                return \"General\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ...,\n",
    "        description=\"Explain your decision about whether this question is answerable and why you chose to route it to the triage contact you chose\",\n",
    "    )\n",
    "    is_answerable_from_context: bool = Field(\n",
    "        ..., description=\"Whether the given response can answer the question from the context provided\"\n",
    "    )\n",
    "    requires_follow_up: bool = Field(\n",
    "        ...,\n",
    "        description=\"Whether the inquiry requires follow-up from the triage contact\",\n",
    "    )\n",
    "    requires_location: bool = Field(\n",
    "        ...,\n",
    "        description=\"Whether the inquiry requires the user to provide their location to be resolved by the triage contact\",\n",
    "    )\n",
    "    requires_photo_or_video: bool = Field(\n",
    "        ...,\n",
    "        description=\"Whether the inquiry requires the user to provide a photo or video to be resolved by the triage contact\",\n",
    "    )\n",
    "    requires_user_contact_info: bool = Field(\n",
    "        ...,\n",
    "        description=\"Whether the inquiry requires the user to provide their contact information to be resolved by the triage contact\",\n",
    "    )\n",
    "    full_response: str = Field(\n",
    "        ...,\n",
    "        description=\"The detailed answer to the question based on the context provided\",\n",
    "    )\n",
    "    final_answer: str = Field(\n",
    "        ...,\n",
    "        description=\"A succinct and concise answer to the question based on the context provided\",\n",
    "    )\n",
    "    route_to: Annotated[Literal[*triage_targets], BeforeValidator(convert_str_to_triage_target)]  # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca595a",
   "metadata": {},
   "source": [
    "#### Task\n",
    "\n",
    "We set things up in this task to allow teams to use either OpenAI or Anthropic models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f358201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL_VENDOR(str, enum.Enum):\n",
    "    ANTHROPIC = \"anthropic\"\n",
    "    OPENAI = \"openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4eabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bt.traced()\n",
    "def synthesize_retrieval(\n",
    "    user_inquiry: str,\n",
    "    retrieval_response: str,\n",
    "    city: str,\n",
    "    vendor: MODEL_VENDOR = MODEL_VENDOR.ANTHROPIC,\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    model_kwargs={},\n",
    ") -> CustomerSupportResponse:\n",
    "    \"\"\"Synthesize the retrieval results into a final answer.\"\"\"\n",
    "\n",
    "    prompt = retrieval_synth_prompt.build(city=city, user_inquiry=user_inquiry, context=retrieval_response)\n",
    "\n",
    "    rsp = None\n",
    "    if vendor == MODEL_VENDOR.ANTHROPIC:\n",
    "        tools = [\n",
    "            {\n",
    "                \"name\": \"customer_support_response\",\n",
    "                \"description\": \"Build CustomerSupportResponse object\",\n",
    "                \"input_schema\": CustomerSupportResponse.model_json_schema(),\n",
    "            }\n",
    "        ]\n",
    "        rsp = wrapped_ac_client.messages.create(\n",
    "            model=model,\n",
    "            system=prompt[\"messages\"].pop(0)[\"content\"],  # type: ignore\n",
    "            messages=prompt[\"messages\"],\n",
    "            tools=tools,\n",
    "            tool_choice={\"type\": \"tool\", \"name\": \"customer_support_response\"},\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        return CustomerSupportResponse(**rsp.content[0].input)\n",
    "\n",
    "    elif vendor == MODEL_VENDOR.OPENAI:\n",
    "        result = wrapped_oai_client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=prompt[\"messages\"],\n",
    "            response_format=CustomerSupportResponse,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        return result.choices[0].message.parsed\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid vendor: {vendor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed[\"final_answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635944e7",
   "metadata": {},
   "source": [
    "Let's try it with Anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp = synthesize_retrieval(\n",
    "    user_inquiry=_example[\"input\"],\n",
    "    retrieval_response=parsed[\"final_answer\"],\n",
    "    city=\"Encinitas\",\n",
    "    model_kwargs={\"max_tokens\": 1024},\n",
    ")\n",
    "rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3034118",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161297a",
   "metadata": {},
   "source": [
    "Let's try it with OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac437e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp = synthesize_retrieval(\n",
    "    user_inquiry=_example[\"input\"],\n",
    "    retrieval_response=parsed[\"final_answer\"],\n",
    "    city=\"Encinitas\",\n",
    "    vendor=MODEL_VENDOR.OPENAI,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_kwargs={},\n",
    ")\n",
    "rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c572f",
   "metadata": {},
   "source": [
    "### Customer support task\n",
    "\n",
    "Let's put our entire workflow together under the `ask_customer_support` task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bt.traced()\n",
    "def ask_customer_support(\n",
    "    user_inquiry: str,\n",
    "    city: str,\n",
    "    search_model: str = \"claude-sonnet-4-20250514\",\n",
    "    synthesis_model: str = \"gpt-4o\",\n",
    "    synthesis_vendor: MODEL_VENDOR = MODEL_VENDOR.OPENAI,\n",
    "    search_model_kwargs={\"max_tokens\": 2048, \"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 1024}},\n",
    "    synthesis_model_kwargs: dict = {},\n",
    ") -> CustomerSupportResponse:\n",
    "    \"\"\"Ask the customer support agent a question.\"\"\"\n",
    "\n",
    "    search_results = ac_web_search(user_inquiry, city, model=search_model, model_kwargs=search_model_kwargs)\n",
    "    customer_support_resp = synthesize_retrieval(\n",
    "        user_inquiry=user_inquiry,\n",
    "        retrieval_response=search_results[\"final_answer\"],\n",
    "        city=city,\n",
    "        vendor=synthesis_vendor,\n",
    "        model=synthesis_model,\n",
    "        model_kwargs=synthesis_model_kwargs,\n",
    "    )\n",
    "\n",
    "    return customer_support_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc20a06",
   "metadata": {},
   "source": [
    "Let's test how this works with a few questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbeccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_request(example):\n",
    "    \"\"\"Process a single customer support request.\"\"\"\n",
    "    city = \"Encinitas\"\n",
    "\n",
    "    with bt.start_span(name=\"request_support_task\") as span:\n",
    "        span.log(input=example[\"input\"])\n",
    "        customer_support_resp = ask_customer_support(\n",
    "            user_inquiry=example[\"input\"],\n",
    "            city=city,\n",
    "            search_model=\"claude-sonnet-4-20250514\",\n",
    "            synthesis_model=\"gpt-4o-mini\",\n",
    "            synthesis_vendor=MODEL_VENDOR.OPENAI,\n",
    "            search_model_kwargs={\"max_tokens\": 2048, \"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 1024}},\n",
    "            synthesis_model_kwargs={},\n",
    "        )\n",
    "\n",
    "        metadata = example.get(\"metadata\", {})\n",
    "        filtered_metadata = {\n",
    "            \"id\": metadata.get(\"id\"),\n",
    "            \"query_source\": metadata.get(\"query_source\"),\n",
    "            \"triage_slug\": metadata.get(\"triage_slug\"),\n",
    "        }\n",
    "\n",
    "        span.log(output=customer_support_resp, metadata=filtered_metadata)\n",
    "        return customer_support_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all test data in parallel\n",
    "print(f\"Processing {len(test_data)} customer support requests in parallel...\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    results = list(executor.map(process_single_request, test_data[:5]))\n",
    "\n",
    "print(f\"Completed processing {len(results)} requests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411cd063",
   "metadata": {},
   "source": [
    "Once we have our traces logged, we can move them into a \"golden [dataset](https://www.braintrust.dev/docs/guides/datasets)\" to build evals on.\n",
    "\n",
    "We'll do this in the Braintrust UI and then use this dataset in our initial experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab918501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bt.init_dataset(project=BT_PROJECT_NAME, name=\"initial_error_analysis\")\n",
    "rows = list(ds)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = rows[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38b8b0",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "So we have our `task` and our `data`, all we need now to start building evals is a way to score how well our task did on each input in our dataset.\n",
    "\n",
    "Braintrust comes with several helpful scorers out of the box via our Autoevals library. Fun fact: you can use them outside of Braintrust as well. In addition to these scoring functions, we can define our own, as demonstrated below, where we configure a reference-based scorer to see how well the task predicts the right contact to route the inquiry to (if available).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_triage_contact(\n",
    "    input: str | None = None,\n",
    "    expected: dict | None = None,\n",
    "    output: CustomerSupportResponse | None = None,\n",
    "    metadata: dict | None = None,\n",
    "    **kwargs,\n",
    ") -> int | None:\n",
    "    if output and metadata and metadata.get(\"triage_slug\"):\n",
    "        return int(output.route_to == metadata.get(\"triage_slug\"))\n",
    "\n",
    "    if output and expected:\n",
    "        return int(expected[\"route_to\"] == output.route_to)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct_triage_contact(\n",
    "    input=row.get(\"input\", \"\"),\n",
    "    output=CustomerSupportResponse.model_validate(row.get(\"expected\", {})),\n",
    "    expected=row.get(\"expected\", None),\n",
    "    metadata=row.get(\"metadata\", None),  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27232a6",
   "metadata": {},
   "source": [
    "## Evals\n",
    "\n",
    "We now have the 3 things required to run an offline eval, a.k.a. an [experiment](https://www.braintrust.dev/docs/guides/experiments)\n",
    "\n",
    "**Data**: Handcoded and Synthetic customer support requests/inquiries \\\n",
    "**Task**: A customer support task that uses two subtasks to route and attempt to answer the request \\\n",
    "**Scorers**: An initial reference-based scorer that scores the response on whether it routed the request to the right contact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "exp_metadata = {\n",
    "    \"city\": \"Encinitas\",\n",
    "    \"search_model\": \"claude-sonnet-4-20250514\",\n",
    "    \"synthesis_model\": \"gpt-4o-mini\",\n",
    "    \"synthesis_vendor\": MODEL_VENDOR.OPENAI,\n",
    "    \"search_model_kwargs\": {\"max_tokens\": 2048, \"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 1024}},\n",
    "    \"synthesis_model_kwargs\": {\"temperature\": 0.75},\n",
    "}\n",
    "await bt.EvalAsync(\n",
    "    name=BT_PROJECT_NAME,\n",
    "    experiment_name=f\"initial_error_analysis_{timestamp}\",\n",
    "    data=rows,  # type: ignore\n",
    "    task=partial(ask_customer_support, **exp_metadata),\n",
    "    metadata=exp_metadata,\n",
    "    scores=[is_correct_triage_contact],  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62270324",
   "metadata": {},
   "source": [
    "We can now start iterating on improving the routing.\n",
    "\n",
    "This can be done in various ways. For example:\n",
    "\n",
    "1. We can change the models and or generation kwargs.\n",
    "2. We can improve the prompts, and so forth.\n",
    "3. We can make corrections to our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04190b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "what_changed = \"fixed routing error in dataset\"\n",
    "\n",
    "exp_metadata = {\n",
    "    \"city\": \"Encinitas\",\n",
    "    \"search_model\": \"claude-sonnet-4-20250514\",\n",
    "    \"synthesis_model\": \"gpt-4o-mini\",\n",
    "    \"synthesis_vendor\": MODEL_VENDOR.OPENAI,\n",
    "    \"search_model_kwargs\": {\"max_tokens\": 2048, \"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 1024}},\n",
    "    \"synthesis_model_kwargs\": {\"temperature\": 0.75},\n",
    "}\n",
    "await bt.EvalAsync(\n",
    "    name=BT_PROJECT_NAME,\n",
    "    experiment_name=f\"initial_error_analysis_{timestamp}\",\n",
    "    data=rows,  # type: ignore\n",
    "    task=partial(ask_customer_support, **exp_metadata),\n",
    "    metadata={**exp_metadata, \"what_changed\": what_changed},\n",
    "    scores=[is_correct_triage_contact],  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d74d7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "From here, we can begin iterating. In particular, we can:\n",
    "\n",
    "- Build a reference-free scorer, something like an LLM-as-Judge, to score routing that can be used both in offline and online-evals\n",
    "- Work with SME's to better identify other failure modes and iterate on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc182c",
   "metadata": {},
   "source": [
    "## Fin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d336b3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
