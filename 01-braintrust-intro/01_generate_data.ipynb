{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d581218e",
   "metadata": {},
   "source": [
    "# A customer support bot - Part 1\n",
    "\n",
    "An introduction to all things Braintrust via a speed-run through building evals for a customer support bot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f891b57",
   "metadata": {},
   "source": [
    "In this demo, we aim to enhance a city's customer support application by developing an AI workflow to streamline the request process and ensure it is routed to the correct department.\n",
    "\n",
    "We propose a simple UI where the user can describe their issue and an AI pipeline that will take that description, route the request to the appropriate contact, prompt the UI for any required information, and provide an answer or informational response if warranted.\n",
    "\n",
    "To build evals for such a pipeline, we need three things:\n",
    "\n",
    "1. Data\n",
    "2. One or more task functions\n",
    "3. One or more scoring functions that tell us how well each row in our dataset did on that task\n",
    "\n",
    "In this notebook, we will work on the data piece.\n",
    "\n",
    "Let's start by importing the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8150e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wgilliam/development/demos/ai_evals_course_202507/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enum\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from textwrap import dedent\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "import anthropic as ac\n",
    "import braintrust as bt\n",
    "import openai as oai\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from braintrust import wrap_anthropic, wrap_openai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, BeforeValidator, Field\n",
    "from thefuzz import process as fuzzy_process\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a7ed5",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Once you're signed up on [Braintrust](https://www.braintrust.dev/) and have set the appropriate API keys in your `.env` file, you're ready to go. For this particular demo, you'll need the following API keys:\n",
    "\n",
    "- `BRAINTRUST_API_KEY`\n",
    "- `OPENAI_API_KEY`\n",
    "- `ANTHROPIC_API_KEY`\n",
    "\n",
    "With that in place, we can create our [Braintrust project](https://www.braintrust.dev/docs/guides/projects) using `braintrust.projects.create()`. This method will return the project if it already exists, or else create it the first time we attempt so send any artifacts it's way.\n",
    "\n",
    "We also define Anthropic and OpenAI clients like usual, as well as a \"wrapped\" version of each client. These \"wrapped\" versions automatically capture usage data (e.g., prompt tokens, etc) in Braintrust when used within the context of a logger or experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da9d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BT_PROJECT_NAME = \"braintrust-intro\"\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "bt_project = bt.projects.create(name=BT_PROJECT_NAME)\n",
    "\n",
    "ac_client = ac.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "oai_client = oai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "wrapped_ac_client = wrap_anthropic(ac_client)\n",
    "wrapped_oai_client = wrap_openai(oai_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c6ce2",
   "metadata": {},
   "source": [
    "**Key takeaways**:\n",
    "\n",
    "1. We use `braintrust.projects.create()` to create or fetch a Braintrust project.\n",
    "2. We define both standard OpenAI and Anthropic clients, as well as wrapped versions of these clients that support automatic logging of their usage data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911eb962",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba6b01",
   "metadata": {},
   "source": [
    "**Objective**: Curate around 100 diverse and realistic customer support requests.\n",
    "\n",
    "> \"Every error analysis starts with _traces_: the full sequence of inputs, outputs, and actions taken by the pipeline for a given input\"\n",
    "\n",
    "The recommendation is to start with ~ 100 traces of diverse user intents, with preference given to real-world data where possible. In this case, we don't have access to such data and so we'll follow the AIE methodology for creating synthetic data. We'll braintrustify this workflow a bit along the way :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d233210",
   "metadata": {},
   "source": [
    "### Step 1: Define dimensions\n",
    "\n",
    "> \"First, before prompting anything, we define key dimensions of the query space... [to] help us systematically vary different aspects of a userâ€™s request\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0ca292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionTuple(BaseModel):\n",
    "    inquiry_type: str = Field(\n",
    "        description=\"What kind of inquiry are they making (e.g. informational_ask, complaint,request_for_action_or_service)\"\n",
    "    )\n",
    "    query_style_and_detail: str = Field(\n",
    "        description=\"The style and detail of the query (e.g. short_keywords_minimal_detail, concise_moderate_detail, verbose_detailed_request)\"\n",
    "    )\n",
    "    customer_persona: str = Field(\n",
    "        description=\"Who is making the request (e.g. business_owner, citizen)\",\n",
    "    )\n",
    "    customer_age: str = Field(\n",
    "        description=\"The age of the person making the request (e.g. senior_over_65, youth_under_18, adult)\",\n",
    "    )\n",
    "\n",
    "\n",
    "class DimensionTuples(BaseModel):\n",
    "    tuples: list[DimensionTuple]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af157a53",
   "metadata": {},
   "source": [
    "### Step 2: Define dimension values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f57b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUPLES_GEN_PROMPT = \"\"\"\\\n",
    "I am designing a customer support chatbot for the city of Encinitas and I want to test it against a diverse\n",
    "range of inquiries citizens might submit. I have provided you with several dimensions and that constitute the parts of\n",
    "such a queries along with a list of possible values for each dimension.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Generate {{{num_tuples_to_generate}}} unique combinations of dimension values for based on the dimensions provided below. \n",
    "- Each combination should represent a different user scenario. \n",
    "- Ensure balanced coverage across all dimensions - don't over-represent any particular value or combination.\n",
    "- Vary the query styles naturally.\n",
    "- Attempt to make the dimension value combinations as realistic as possible.\n",
    "- Never generate a tuple where the customer_persona is a business_owner and the customer_age is youth_under_18.\n",
    "\n",
    "## Dimensions\n",
    "\n",
    "inquiry_type:\n",
    "- informational_ask\n",
    "- complaint\n",
    "- request_for_action_or_service\n",
    "\n",
    "query_style_and_detail:\n",
    "- concise_moderate_detail: [includes some details relevant to the `inquiry_topic`, e.g., location, names, etc.]\n",
    "- verbose_detailed_request: [includes specific details relevant to the `inquiry_topic`, e.g., location, names, etc.]\n",
    "- short_keywords_minimal_details\n",
    "\n",
    "customer_persona: Who is making the request\n",
    "- business_owner\n",
    "- citizen\n",
    "\n",
    "customer_age: The age of the person making the request\n",
    "- senior_over_65\n",
    "- youth_under_18\n",
    "- adult\n",
    "\n",
    "Generate {{{num_tuples_to_generate}}} unique dimension tuples following these patterns. Remember to maintain balanced diversity across all dimensions.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776913fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TUPLES_GEN_PROMPT.replace(\"{{{num_tuples_to_generate}}}\", \"10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf32d0d",
   "metadata": {},
   "source": [
    "Create a [versioned prompt](https://www.braintrust.dev/docs/guides/functions/prompts) and save it to Braintrust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a340f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n",
    "try:\n",
    "    tuples_gen_prompt.build(num_tuples_to_generate=20)\n",
    "except Exception as e:\n",
    "    bt_tuples_gen_prompt = bt_project.prompts.create(\n",
    "        name=\"DimensionTuplesGenPrompt\",\n",
    "        slug=\"dimension-tuples-gen-prompt\",\n",
    "        description=\"Prompt for generating dimension tuples\",\n",
    "        model=\"claude-4-sonnet-20250514\",\n",
    "        messages=[{\"role\": \"user\", \"content\": TUPLES_GEN_PROMPT}],\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "\n",
    "    bt_project.publish()\n",
    "    tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789647d",
   "metadata": {},
   "source": [
    "**Key takeaways**:\n",
    "\n",
    "1. We can create and manage versions of prompts using the SDK or through the UI.\n",
    "2. We can retrieve any prompt version via the SDK for use in our code (the latest version is returned by default).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc0119",
   "metadata": {},
   "source": [
    "With this in place, we can engage our domain experts in the prompt-building process via our [playgrounds](https://www.braintrust.dev/docs/guides/playground) and use our eval-specific AI assistant, [Loop](https://www.braintrust.dev/docs/guides/loop).\n",
    "\n",
    "We'll prompt Loop to improve our \"prompt\" like this:\n",
    "\n",
    "> \"Help me improve this prompt to capture all the different dimensions a customer support inquiry may have for the city of Encinitas.\n",
    ">\n",
    "> The dimensions and their values should represent realistic aspects of a customer support request they may get\"\n",
    "\n",
    "<img src=\"./data/dim-tuples-gen-playground-loop.png\" width=\"800\"/>\n",
    "\n",
    "We can then get our updated prompt, make changes to the structured output definition, and generate some data!\n",
    "\n",
    "**Key takeaways**:\n",
    "\n",
    "1. Besides optimizing our prompts, Loop can also enhance our scorers and assist in curating datasets for evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac227e",
   "metadata": {},
   "source": [
    "Fetch our improved prompt and update our Pydantic model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8da9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"dimension-tuples-gen-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb7ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am designing a customer support chatbot for the city of Encinitas and I want to test it against a diverse range of inquiries citizens might submit. I have provided you with several dimensions that constitute the parts of such queries along with a list of possible values for each dimension.\n",
      "\n",
      "## Instructions\n",
      "\n",
      "Generate 20 unique combinations of dimension values based on the dimensions provided below. \n",
      "- Each combination should represent a different user scenario. \n",
      "- Ensure balanced coverage across all dimensions - don't over-represent any particular value or combination.\n",
      "- Vary the query styles naturally.\n",
      "- Attempt to make the dimension value combinations as realistic as possible.\n",
      "- Never generate a tuple where the customer_persona is a business_owner and the customer_age is youth_under_18.\n",
      "\n",
      "## Dimensions\n",
      "\n",
      "inquiry_type:\n",
      "- informational_ask\n",
      "- complaint\n",
      "- request_for_action_or_service\n",
      "- permit_application\n",
      "- service_status_check\n",
      "\n",
      "urgency_level:\n",
      "- emergency: [immediate safety concern or service outage]\n",
      "- urgent: [needs attention within 24-48 hours]\n",
      "- routine: [standard inquiry or request, no rush]\n",
      "- follow_up: [checking on previous request or inquiry]\n",
      "\n",
      "query_style_and_detail:\n",
      "- concise_moderate_detail: [includes some details relevant to the service_category, e.g., location, specific issue]\n",
      "- verbose_detailed_request: [includes specific details relevant to the service_category, e.g., exact location, timeline, reference numbers]\n",
      "- short_keywords_minimal_details: [brief, lacks context or specifics]\n",
      "\n",
      "customer_persona: Who is making the request\n",
      "- resident: [lives in Encinitas]\n",
      "- business_owner: [operates business in Encinitas]\n",
      "- visitor: [tourist or temporary visitor]\n",
      "- property_owner: [owns property but may not live in Encinitas]\n",
      "\n",
      "customer_age: The age of the person making the request\n",
      "- senior_over_65\n",
      "- youth_under_18\n",
      "- adult_18_64\n",
      "\n",
      "communication_preference:\n",
      "- phone_call\n",
      "- email\n",
      "- online_portal\n",
      "- in_person_visit\n",
      "- social_media\n",
      "\n",
      "time_sensitivity:\n",
      "- same_day_response_needed\n",
      "- within_week_response_ok\n",
      "- no_specific_timeline\n",
      "\n",
      "Generate 20 unique dimension tuples following these patterns. Remember to maintain balanced diversity across all dimensions and ensure combinations make realistic sense for Encinitas municipal services.\n"
     ]
    }
   ],
   "source": [
    "_p = tuples_gen_prompt.build(num_tuples_to_generate=20)\n",
    "print(_p[\"messages\"][0][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7e1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionTuple(BaseModel):\n",
    "    inquiry_type: str = Field(\n",
    "        description=\"What kind of inquiry are they making (e.g. informational_ask, complaint, request_for_action_or_service, permit_application, service_status_check)\"\n",
    "    )\n",
    "    urgency_level: str = Field(\n",
    "        description=\"The urgency level of the request (e.g. emergency, urgent, routine, follow_up)\",\n",
    "    )\n",
    "    query_style_and_detail: str = Field(\n",
    "        description=\"The style and detail of the query (e.g. concise_moderate_detail, verbose_detailed_request, short_keywords_minimal_details)\"\n",
    "    )\n",
    "    customer_persona: str = Field(\n",
    "        description=\"Who is making the request (e.g. resident, business_owner, visitor, property_owner)\",\n",
    "    )\n",
    "    customer_age: str = Field(\n",
    "        description=\"The age of the person making the request (e.g. senior_over_65, youth_under_18, adult_18_64)\",\n",
    "    )\n",
    "    communication_preference: str = Field(\n",
    "        description=\"Preferred communication method (e.g. phone_call, email, online_portal, in_person_visit, social_media)\"\n",
    "    )\n",
    "    time_sensitivity: str = Field(\n",
    "        description=\"How quickly a response is needed (e.g. same_day_response_needed, within_week_response_ok, no_specific_timeline)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class DimensionTuples(BaseModel):\n",
    "    tuples: list[DimensionTuple]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ee383",
   "metadata": {},
   "source": [
    "### Step 3: Use an LLM to generate N unique combinations of these dimension values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848b4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_data_dimension_tuples(num_tuples: int = 20, model: str = \"gpt-4o-mini\", model_kwargs: dict = {}):\n",
    "    \"\"\"Generate a list of dimension tuples based on the provided prompt.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    prompt = tuples_gen_prompt.build(num_tuples_to_generate=num_tuples)\n",
    "\n",
    "    rsp = oai_client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=prompt[\"messages\"],\n",
    "        response_format=DimensionTuples,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "\n",
    "    tuples_list: DimensionTuples = rsp.choices[0].message.parsed  # type: ignore\n",
    "\n",
    "    unique_tuples = []\n",
    "    seen = set()\n",
    "\n",
    "    for tup in tuples_list.tuples:\n",
    "        tuple_str = tup.model_dump_json()\n",
    "        if tuple_str in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(tuple_str)\n",
    "        unique_tuples.append(tup)\n",
    "\n",
    "    bt_experiment = bt.init(project=BT_PROJECT_NAME, experiment=f\"synth_tuples_it_{timestamp}\")\n",
    "    for uniq_tup in unique_tuples:\n",
    "        with bt_experiment.start_span(name=\"generate_dimension_tuples\") as span:\n",
    "            span.log(input=prompt[\"messages\"], output=uniq_tup, metadata=dict(model=model, model_kwargs=model_kwargs))\n",
    "\n",
    "    summary = bt_experiment.summarize(summarize_scores=False)\n",
    "    return summary, rsp.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c67242",
   "metadata": {},
   "source": [
    "**Key Takeaways**:\n",
    "\n",
    "1. We use `braintrust.init` to manually create a new experiment.\n",
    "2. We generate a trace in the form of a single span, adding information for `input`, `output`, and `metadata`.\n",
    "3. We obtain the experiment summary via `braintrust.summarize` to review the experiment results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d83c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "See results for synth_tuples_it_20250724_1057 at https://www.braintrust.dev/app/aie-course-2025/p/braintrust-intro/experiments/synth_tuples_it_20250724_1057\n",
      "tuples=[DimensionTuple(inquiry_type='informational_ask', urgency_level='routine', query_style_and_detail='concise_moderate_detail', customer_persona='resident', customer_age='adult_18_64', communication_preference='email', time_sensitivity='within_week_response_ok'), DimensionTuple(inquiry_type='complaint', urgency_level='urgent', query_style_and_detail='verbose_detailed_request', customer_persona='visitor', customer_age='adult_18_64', communication_preference='phone_call', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='request_for_action_or_service', urgency_level='emergency', query_style_and_detail='concise_moderate_detail', customer_persona='resident', customer_age='adult_18_64', communication_preference='in_person_visit', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='permit_application', urgency_level='routine', query_style_and_detail='verbose_detailed_request', customer_persona='property_owner', customer_age='senior_over_65', communication_preference='online_portal', time_sensitivity='no_specific_timeline'), DimensionTuple(inquiry_type='service_status_check', urgency_level='follow_up', query_style_and_detail='short_keywords_minimal_details', customer_persona='business_owner', customer_age='adult_18_64', communication_preference='email', time_sensitivity='within_week_response_ok'), DimensionTuple(inquiry_type='informational_ask', urgency_level='routine', query_style_and_detail='short_keywords_minimal_details', customer_persona='visitor', customer_age='youth_under_18', communication_preference='social_media', time_sensitivity='no_specific_timeline'), DimensionTuple(inquiry_type='complaint', urgency_level='urgent', query_style_and_detail='verbose_detailed_request', customer_persona='resident', customer_age='adult_18_64', communication_preference='phone_call', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='request_for_action_or_service', urgency_level='routine', query_style_and_detail='concise_moderate_detail', customer_persona='property_owner', customer_age='senior_over_65', communication_preference='email', time_sensitivity='within_week_response_ok'), DimensionTuple(inquiry_type='permit_application', urgency_level='urgent', query_style_and_detail='verbose_detailed_request', customer_persona='business_owner', customer_age='adult_18_64', communication_preference='online_portal', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='service_status_check', urgency_level='follow_up', query_style_and_detail='concise_moderate_detail', customer_persona='resident', customer_age='adult_18_64', communication_preference='in_person_visit', time_sensitivity='no_specific_timeline'), DimensionTuple(inquiry_type='informational_ask', urgency_level='emergency', query_style_and_detail='short_keywords_minimal_details', customer_persona='resident', customer_age='youth_under_18', communication_preference='phone_call', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='complaint', urgency_level='routine', query_style_and_detail='concise_moderate_detail', customer_persona='property_owner', customer_age='adult_18_64', communication_preference='social_media', time_sensitivity='within_week_response_ok'), DimensionTuple(inquiry_type='request_for_action_or_service', urgency_level='urgent', query_style_and_detail='verbose_detailed_request', customer_persona='visitor', customer_age='adult_18_64', communication_preference='in_person_visit', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='permit_application', urgency_level='routine', query_style_and_detail='concise_moderate_detail', customer_persona='resident', customer_age='adult_18_64', communication_preference='email', time_sensitivity='no_specific_timeline'), DimensionTuple(inquiry_type='service_status_check', urgency_level='urgent', query_style_and_detail='verbose_detailed_request', customer_persona='business_owner', customer_age='adult_18_64', communication_preference='online_portal', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='informational_ask', urgency_level='follow_up', query_style_and_detail='short_keywords_minimal_details', customer_persona='property_owner', customer_age='senior_over_65', communication_preference='social_media', time_sensitivity='within_week_response_ok'), DimensionTuple(inquiry_type='complaint', urgency_level='emergency', query_style_and_detail='concise_moderate_detail', customer_persona='senior_over_65', customer_age='senior_over_65', communication_preference='in_person_visit', time_sensitivity='same_day_response_needed'), DimensionTuple(inquiry_type='request_for_action_or_service', urgency_level='routine', query_style_and_detail='verbose_detailed_request', customer_persona='resident', customer_age='adult_18_64', communication_preference='email', time_sensitivity='no_specific_timeline'), DimensionTuple(inquiry_type='permit_application', urgency_level='urgent', query_style_and_detail='short_keywords_minimal_details', customer_persona='visitor', customer_age='adult_18_64', communication_preference='online_portal', time_sensitivity='same_day_response_needed')]\n"
     ]
    }
   ],
   "source": [
    "exp_summary, dim_tuples = generate_synth_data_dimension_tuples(20)\n",
    "\n",
    "print(exp_summary)\n",
    "print(dim_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91442ec6",
   "metadata": {},
   "source": [
    "### Step 4: Remove invalid dimension tuples (human/SME review)\n",
    "\n",
    "We'll do this in the Braintrust UI with [human review](https://www.braintrust.dev/docs/guides/human-review).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4388eb9",
   "metadata": {},
   "source": [
    "<img src=\"./data/dim-tuples-human-review.png\" width=\"800\"/>\n",
    "\n",
    "**Key takeaways**:\n",
    "\n",
    "1. To set up scorers for human review, navigate to \"Configuration\" > \"Human Review\".\n",
    "2. Free-form scorers can be configured to record data in the metadata.\n",
    "3. Human review scorers can be used in BTQL queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b66a28",
   "metadata": {},
   "source": [
    "### Step 5: Demonstrate an approach to building + 20 queries with the help of a SME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f521eedc",
   "metadata": {},
   "source": [
    "Working with an SME and ChatGPT, we were able to capture all of the contacts, customer support requests get routed, and a description of the types of inquiries each gets routed their way. We even curated 5 example support requests for each of these contacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7e6fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['parks_recreation',\n",
       " 'general',\n",
       " 'fire_prevention',\n",
       " 'human_resources',\n",
       " 'traffic_engineering',\n",
       " 'code_enforcement',\n",
       " 'san_dieguito_water_district',\n",
       " 'public_works',\n",
       " 'san_diego_humane_society',\n",
       " 'homeless_solutions',\n",
       " 'san_diego_county_vector_control']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_support_areas = json.load(open(\"./data/dept_support_areas.json\"))\n",
    "\n",
    "triage_targets = list(set([route[\"slug\"] for route in dept_support_areas]))\n",
    "\n",
    "print(len(triage_targets))\n",
    "triage_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75e4046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Works (public_works)\n",
      "- Deceased animals\n",
      "- Graffiti on public property\n",
      "- Water leak (non-emergency)\n",
      "- Streetlight outages\n",
      "- Pothole repairs\n",
      "-> I saw a dead raccoon on Melba Road todayâ€”can someone remove it?\n",
      "-> Thereâ€™s new graffiti on the sidewalk wall along South Coast Highway.\n",
      "-> A small water leak is pooling near the fire hydrant on Encinitas Blvd.\n",
      "-> The streetlight in front of 450 Quail Gardens Dr has been out for 3 nights.\n",
      "-> Thereâ€™s a deep pothole on Manchester Ave that's damaging cars.\n",
      "\n",
      "Code Enforcement (code_enforcement)\n",
      "- Abandoned vehicles\n",
      "- Illegal signs or banners\n",
      "- Noise complaints\n",
      "- Trash or junk on private property\n",
      "- Homeless overnight camping\n",
      "-> Thereâ€™s a broken-down RV parked on Citrus Ave for over two weeks.\n",
      "-> Someone put up a political banner on private property with no permit.\n",
      "-> Neighbors at 2â€¯a.m. are playing loud music by the pool every weekend.\n",
      "-> The vacant lot next to Sunset View has piles of old furniture.\n",
      "-> A homeless encampment is forming under the 101 overpass near Cardiff.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, triage_point in enumerate(dept_support_areas):\n",
    "    if idx >= 2:\n",
    "        break\n",
    "    print(f\"{triage_point['name']} ({triage_point['slug']})\")\n",
    "    print(\"- \" + \"\\n- \".join(triage_point[\"support_areas\"][:5]))\n",
    "    print(\"-> \" + \"\\n-> \".join(triage_point[\"examples\"][:5]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b334a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triage targets: 11\n",
      "Total examples: 55\n",
      "First 5 examples for 'public_works': ['I saw a dead raccoon on Melba Road todayâ€”can someone remove it?', 'Thereâ€™s new graffiti on the sidewalk wall along South Coast Highway.', 'A small water leak is pooling near the fire hydrant on Encinitas Blvd.', 'The streetlight in front of 450 Quail Gardens Dr has been out for 3 nights.', \"Thereâ€™s a deep pothole on Manchester Ave that's damaging cars.\"]\n"
     ]
    }
   ],
   "source": [
    "triage_examples = {}\n",
    "for triage_contact in dept_support_areas:\n",
    "    triage_target = triage_contact[\"slug\"]\n",
    "    if triage_target not in triage_examples:\n",
    "        triage_examples[triage_target] = {\"name\": triage_contact[\"name\"], \"support_areas\": triage_contact[\"support_areas\"], \"examples\": []}\n",
    "    triage_examples[triage_target][\"examples\"].extend(triage_contact[\"examples\"])\n",
    "\n",
    "print(f\"Total triage targets: {len(triage_examples)}\")\n",
    "print(f\"Total examples: {sum(len(data['examples']) for data in triage_examples.values())}\")\n",
    "print(f\"First 5 examples for '{list(triage_examples.keys())[0]}': {triage_examples[list(triage_examples.keys())[0]]['examples'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16b0eb",
   "metadata": {},
   "source": [
    "### Step 6. Scale up 100 or more tuples + queries using an LLM\n",
    "\n",
    "We can use the \"[BTQL](https://www.braintrust.dev/docs/reference/btql) Sandbox\" to help us construct a query to get the \"good\" dimension tuples from our annotation exercise, and then use that query to get those records to build some synthetic queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1645afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'communication_preference': 'online_portal',\n",
       "  'customer_age': 'adult_18_64',\n",
       "  'customer_persona': 'visitor',\n",
       "  'inquiry_type': 'permit_application',\n",
       "  'query_style_and_detail': 'short_keywords_minimal_details',\n",
       "  'time_sensitivity': 'same_day_response_needed',\n",
       "  'urgency_level': 'urgent'},\n",
       " {'communication_preference': 'email',\n",
       "  'customer_age': 'adult_18_64',\n",
       "  'customer_persona': 'resident',\n",
       "  'inquiry_type': 'request_for_action_or_service',\n",
       "  'query_style_and_detail': 'verbose_detailed_request',\n",
       "  'time_sensitivity': 'no_specific_timeline',\n",
       "  'urgency_level': 'routine'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_valid_dimension_tuples():\n",
    "    cursor = None\n",
    "    while True:\n",
    "        response = requests.post(\n",
    "            \"https://staging-api.braintrust.dev/btql\",\n",
    "            json={\n",
    "                \"query\": dedent(\"\"\"\n",
    "                        select: output\n",
    "                        from: experiment('6006d3ae-ccea-48bf-b7ba-d4d27b18e271')\n",
    "                        filter: scores.\"is_good\" = 1\n",
    "                \"\"\")\n",
    "                + (f\" | cursor: '{cursor}'\" if cursor else \"\"),\n",
    "                \"use_brainstore\": True,\n",
    "                \"brainstore_realtime\": True,  # Include the latest realtime data, but a bit slower.\n",
    "            },\n",
    "            headers={\"Authorization\": \"Bearer \" + os.environ[\"BRAINTRUST_API_KEY\"]},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        data = response_json.get(\"data\", [])\n",
    "        cursor = response_json.get(\"cursor\")\n",
    "\n",
    "        return [row[\"output\"] for row in data]\n",
    "\n",
    "\n",
    "valid_dim_tuples = get_valid_dimension_tuples()\n",
    "\n",
    "print(len(valid_dim_tuples))\n",
    "valid_dim_tuples[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33602a4",
   "metadata": {},
   "source": [
    "**Key takeaways**:\n",
    "\n",
    "1. We can use BTQL to query our logs, experiments, and datasets.\n",
    "2. Use the \"BTQL sandbox\" to build and test your queries before putting them in code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bfc2bb",
   "metadata": {},
   "source": [
    "Create a versioned prompt and save it to Braintrust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c14d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTH_DATA_GEN_PROMPT = \"\"\"\\\n",
    "I am designing a customer support chatbot for the city of Encinitas and I want to test it against a diverse\n",
    "range of realistic inquiries citizens that would appropriately be routed to this contact:\n",
    "\n",
    "Contact: {{{contact_name}}}\n",
    "Support Areas: {{{support_areas}}}\n",
    "\n",
    "## Objective\n",
    "\n",
    "Produce {{{num_queries_to_generate}}} additional natural language customer support requests using a sample of actual customer support requests \n",
    "below, but augmented to have one of the characteristics listed below:\n",
    "\n",
    "==== Inquiry Characteristics =====\n",
    "{{{dimension_tuple_json}}}\n",
    "\n",
    "===== Example Inquiries =====\n",
    "{{{example_inquiries}}}\n",
    "\n",
    "## Instructions\n",
    "To produce each inquiry, follow these steps:\n",
    "1. Choose a random example from the list of example inquiries above.\n",
    "2. Choose a random record from the list of inquiry characteristics above.\n",
    "3. Augment the example inquiry to have the chosen characteristic of that record.\n",
    "4. Return the augmented inquiry.\n",
    "\n",
    "The queries should:\n",
    "1. Sound like real users asking for assistance\n",
    "2. Naturally incorporate all the dimension values\n",
    "3. Vary in style and detail level\n",
    "4. Be realistic and practical\n",
    "5. Change any named entities (locations, addresses, street names, person names, etc...) to diversify the content\n",
    "5. Include natural variations in typing style, such as:\n",
    "   - Some queries in all lowercase\n",
    "   - Some with random capitalization\n",
    "   - Some with common typos\n",
    "   - Some with missing punctuation\n",
    "   - Some with extra spaces or missing spaces\n",
    "   - Some with emojis or text speak\n",
    "\n",
    "Here are examples of realistic query variations for a request to get a pothole fixed from \n",
    "an adult, business_owner, concise_moderate_detail:\n",
    "\n",
    "Proper formatting:\n",
    "- \"There is a huge pothole on the corner of 123 Main St. It's been there for weeks affecting customers trying to park nearby\"\n",
    "- \"Can someone please fix the pothole on 123 Main St.\"\n",
    "\n",
    "All lowercase:\n",
    "- \"need someone to fix the pothole on 123 main st.\"\n",
    "- \"can a crew come out and fix the pothole on the corner of 123 main st. and grand ave.\"\n",
    "\n",
    "Random caps:\n",
    "- \"NEED someone to fix the pothole on 123 main st. ASAP\"\n",
    "- \"can a crew come out and fix the pothole on the corner of 123 main st. and grand ave??? It needs to happen NOW! Like today!\"\n",
    "\n",
    "Common typos:\n",
    "- \"need someone to fx the pothol on 123 main st. asap pleze!!!\"\n",
    "- \"Can a crew come out and fx the pothole on the corner of 123 main st. & grand ave??? thx much!\"\n",
    "\n",
    "Missing punctuation:\n",
    "- \"need someone to fx the pothole on 123 main st asap plz\"\n",
    "- \"Can a crew come out and fix the pothole on the corner of 123 main st & grand ave ... thx much\"\n",
    "\n",
    "With emojis/text speak:\n",
    "- \"the pothole needs to be fixed now on 123 main st. and grand ave! ðŸ¥—\"\n",
    "- \"pls help get the pothole on 123 main st. & grand ave fixed thx\"\n",
    "\n",
    "Generate {{{num_queries_to_generate}}} unique queries,varying the text style naturally.\"\"\"\n",
    "\n",
    "\n",
    "# print(\n",
    "#     (\n",
    "#         SYNTH_DATA_GEN_PROMPT.replace(\"{{{num_queries_to_generate}}}\", \"4\")\n",
    "#         .replace(\"{{{dimension_tuple_json}}}\", json.dumps(valid_dim_tuples[:4], indent=2))\n",
    "#         .replace(\"{{{example_inquiries}}}\", \"- \" + \"\\n- \".join(triage_examples[\"public_works\"][\"examples\"][:5]))\n",
    "#         .replace(\"{{{contact_name}}}\", triage_examples[\"public_works\"][\"name\"])\n",
    "#         .replace(\"{{{support_areas}}}\", \", \".join(triage_examples[\"public_works\"][\"support_areas\"]))\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "123dc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_query_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"synth-query-gen-prompt\")\n",
    "try:\n",
    "    synth_query_gen_prompt.prompt\n",
    "except Exception as e:\n",
    "    bt_syth_query_gen_prompt = bt_project.prompts.create(\n",
    "        name=\"SynthQueryGenPrompt\",\n",
    "        slug=\"synth-query-gen-prompt\",\n",
    "        description=\"Prompt for generating synthetic queries\",\n",
    "        model=\"claude-4-sonnet-20250514\",\n",
    "        messages=[{\"role\": \"user\", \"content\": SYNTH_DATA_GEN_PROMPT}],\n",
    "        if_exists=\"replace\",\n",
    "    )\n",
    "\n",
    "    bt_project.publish()\n",
    "    synth_query_gen_prompt = bt.load_prompt(project=BT_PROJECT_NAME, slug=\"synth-query-gen-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37924943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _p = synth_query_gen_prompt.build(\n",
    "#     num_queries_to_generate=4,\n",
    "#     dimension_tuple_json=json.dumps(valid_dim_tuples[:4], indent=2),\n",
    "#     example_inquiries=\"- \" + \"\\n- \".join(triage_examples[\"public_works\"][\"examples\"][:5]),\n",
    "#     contact_name=triage_examples[\"public_works\"][\"name\"],\n",
    "#     support_areas=\", \".join(triage_examples[\"public_works\"][\"support_areas\"]),\n",
    "# )\n",
    "\n",
    "# _p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa2f69",
   "metadata": {},
   "source": [
    "Generate synthetic data we can later run through our customer support bot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077da744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryList(BaseModel):\n",
    "    queries: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "133d104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synth_queries(triage_slug: str, num_queries: int = 10, model: str = \"gpt-4o-mini\", model_kwargs: dict = {}) -> dict:\n",
    "    random_dim_tuples = random.sample(valid_dim_tuples, min(num_queries, len(valid_dim_tuples)))\n",
    "\n",
    "    prompt = synth_query_gen_prompt.build(\n",
    "        num_queries_to_generate=num_queries,\n",
    "        dimension_tuple_json=json.dumps(random_dim_tuples, indent=2),\n",
    "        example_inquiries=\"- \" + \"\\n- \".join(triage_examples[triage_slug][\"examples\"][:5]),\n",
    "        contact_name=triage_examples[triage_slug][\"name\"],\n",
    "        support_areas=\", \".join(triage_examples[triage_slug][\"support_areas\"]),\n",
    "    )\n",
    "\n",
    "    rsp = oai_client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=prompt[\"messages\"],\n",
    "        response_format=QueryList,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "\n",
    "    query_list: QueryList = rsp.choices[0].message.parsed  # type: ignore\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt[\"messages\"],\n",
    "        \"triage_slug\": triage_slug,\n",
    "        \"sampled_dim_tuples\": random_dim_tuples,\n",
    "        \"handcoded_queries\": triage_examples[triage_slug][\"examples\"],\n",
    "        \"synth_queries\": query_list.queries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d7432cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsp = generate_synth_queries(\"public_works\", num_queries=10)\n",
    "\n",
    "# for q in rsp[\"handcoded_queries\"]:\n",
    "#     print(q)\n",
    "# print(\"-\" * 100)\n",
    "# for q in rsp[\"synth_queries\"]:\n",
    "#     print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61b6015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries_parallel(triage_targets: list[str], num_queries: int = 10, model: str = \"gpt-4o-mini\", model_kwargs: dict = {}):\n",
    "    \"\"\"Generate queries in parallel for all dimension tuples.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "    print(f\"Generating {num_queries} queries each for {len(triage_targets)} triage targets...\")\n",
    "    # Run in parallel\n",
    "    worker = partial(generate_synth_queries, num_queries=num_queries, model=model, model_kwargs=model_kwargs)\n",
    "    responses = list(ThreadPoolExecutor(max_workers=MAX_WORKERS).map(worker, triage_targets))\n",
    "\n",
    "    # Add query items\n",
    "    all_queries = []\n",
    "    for response in responses:\n",
    "        prompt = response[\"prompt\"]\n",
    "        triage_slug = response[\"triage_slug\"]\n",
    "\n",
    "        queries = [{\"prompt\": prompt, \"triage_slug\": triage_slug, \"query\": q, \"query_source\": \"synth\"} for q in response[\"synth_queries\"]]\n",
    "        queries.extend(\n",
    "            [{\"prompt\": prompt, \"triage_slug\": triage_slug, \"query\": q, \"query_source\": \"handcoded\"} for q in response[\"handcoded_queries\"]]\n",
    "        )\n",
    "\n",
    "        all_queries.extend(queries)\n",
    "\n",
    "    # Add to experiment\n",
    "    bt_experiment = bt.init(project=BT_PROJECT_NAME, experiment=f\"add_queries_it_{timestamp}\")\n",
    "    query_id = 1\n",
    "\n",
    "    for query_item in all_queries:\n",
    "        qid = f\"{timestamp}_{query_id:03d}\"\n",
    "        query_id += 1\n",
    "\n",
    "        with bt_experiment.start_span(name=\"add_query\") as span:\n",
    "            span.log(\n",
    "                input=query_item[\"prompt\"],\n",
    "                output=query_item[\"query\"],\n",
    "                metadata={\n",
    "                    \"id\": qid,\n",
    "                    \"triage_slug\": query_item[\"triage_slug\"],\n",
    "                    \"query_source\": query_item[\"query_source\"],\n",
    "                    \"model\": model,\n",
    "                    \"model_kwargs\": model_kwargs,\n",
    "                },\n",
    "            )\n",
    "\n",
    "    summary = bt_experiment.summarize(summarize_scores=False)\n",
    "    return summary, queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9a1edc",
   "metadata": {},
   "source": [
    "**Key takeaways**:\n",
    "\n",
    "1. Use `braintrust.init()` to manually create a new experiment.\n",
    "2. Add a distinct trace as a single span, including information for `input`, `output`, and `metadata`.\n",
    "3. Retrieve the experiment summary with `braintrust.summarize()` to review the experiment results..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b212eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 queries each for 11 triage targets...\n",
      "15\n",
      "\n",
      "=========================SUMMARY=========================\n",
      "See results for add_queries_it_20250724_1103 at https://www.braintrust.dev/app/aie-course-2025/p/braintrust-intro/experiments/add_queries_it_20250724_1103\n"
     ]
    }
   ],
   "source": [
    "summary, queries = generate_queries_parallel(triage_targets, num_queries=10, model=\"gpt-4o-mini\")\n",
    "# summary, queries = generate_queries_parallel(triage_targets[:2], num_queries=10, model=\"gpt-4o-mini\")\n",
    "\n",
    "print(len(queries))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981281b",
   "metadata": {},
   "source": [
    "### Step 7. Remove invalid queries (human/SME review)\n",
    "\n",
    "We'll do this in the Braintrust UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf16c7",
   "metadata": {},
   "source": [
    "<img src=\"./data/synth-queries-human-review.png\" width=\"800\"/>\n",
    "\n",
    "**Key takeaways**:\n",
    "\n",
    "1. We can apply filters and groups to better look at the data we are interested in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d74d7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the \"02_tasks_and_evals\" notebook we will do the following:\n",
    "\n",
    "- Define task(s) for our evals\n",
    "- Curate a dataset to use for running experiments\n",
    "- Define scorer(s)\n",
    "- Run evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc182c",
   "metadata": {},
   "source": [
    "## Fin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d336b3a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
