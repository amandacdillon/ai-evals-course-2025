{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Homework 3: LLM-as-Judge for Recipe Bot Evaluation\n",
        "\n",
        "In this notebook, we will cover:\n",
        "\n",
        "- Creating train, validation, and test datasets from labeled traces\n",
        "- Fetching experiment data to calculate TPR and TNR on those datasets\n",
        "- Running evals on unlabled traces using an LLM judge we create in a Braintrust playground\n",
        "- Using judgy to calibrate our LLM judge predictions\n",
        "\n",
        "Let's start by importing the required libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split configuration:\n",
            "Train: 15.0%\n",
            "Validation: 40.0%\n",
            "Test: 45.0%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "from judgy import estimate_success_rate\n",
        "\n",
        "from backend.utils import get_agent_response\n",
        "\n",
        "sys.path.append(os.path.abspath(\"..\"))\n",
        "import braintrust as bt\n",
        "import openai as oai\n",
        "import requests\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Configuration - make percentages configurable\n",
        "TRAIN_SIZE = 0.15  # 15%\n",
        "VALIDATION_SIZE = 0.40  # 40%\n",
        "TEST_SIZE = 0.45  # 45%\n",
        "\n",
        "# Verify percentages sum to 1\n",
        "assert abs(TRAIN_SIZE + VALIDATION_SIZE + TEST_SIZE - 1.0) < 1e-10, \"Percentages must sum to 100%\"\n",
        "\n",
        "print(f\"Split configuration:\")\n",
        "print(f\"Train: {TRAIN_SIZE:.1%}\")\n",
        "print(f\"Validation: {VALIDATION_SIZE:.1%}\")\n",
        "print(f\"Test: {TEST_SIZE:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded dataset with 101 rows and 11 columns\n",
            "Columns: ['query', 'dietary_restriction', 'response', 'success', 'error', 'trace_id', 'query_id', 'label', 'reasoning', 'confidence', 'labeled']\n",
            "\n",
            "Original label distribution:\n",
            "label\n",
            "PASS    75\n",
            "FAIL    26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Original label proportions:\n",
            "label\n",
            "PASS    0.742574\n",
            "FAIL    0.257426\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Load the labeled traces data\n",
        "data_path = \"data/labeled_traces.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"Loaded dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# Check the distribution of labels\n",
        "label_counts = df[\"label\"].value_counts()\n",
        "print(f\"\\nOriginal label distribution:\")\n",
        "print(label_counts)\n",
        "print(f\"\\nOriginal label proportions:\")\n",
        "print(label_counts / len(df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Get & Label Your Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of time we're going to assume this is already done.\n",
        "\n",
        "A great way to accomplish this within Braintrust is to use the following workflow that we've demonstrated in previous lessons:\n",
        "\n",
        "1. Use an LLM to help curate relevant traces for the failure mode you are targeting.\n",
        "\n",
        "2. Generate traces by calling `get_agent_response`\n",
        "\n",
        "3. In Braintrust:\n",
        "\n",
        "- Move those logs to a dataset\n",
        "- Create a \"Human Review\" score called \"label\" that can be set to \"PASS\" or \"FAIL\" (have it write to `metadata.label`)\n",
        "- Review the traces\n",
        "- Move them to a dataset\n",
        "\n",
        "4. Download the dataset created at the end of step 3 as a .csv named `labeled_traces.csv`\n",
        "\n",
        "There are many ways to accomplish this if you're so bold to give it a go. The above is just a recommended strategy that works :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Split Your Labeled Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_analyze_data(csv_path):\n",
        "    \"\"\"Load the labeled traces data and return basic statistics.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    pass_df = df[df[\"label\"] == \"PASS\"].reset_index(drop=True)\n",
        "    fail_df = df[df[\"label\"] == \"FAIL\"].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Loaded dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
        "    print(f\"Total PASS: {len(pass_df)}, Total FAIL: {len(fail_df)}\")\n",
        "\n",
        "    original_ratio = len(pass_df) / len(fail_df) if len(fail_df) > 0 else float(\"inf\")\n",
        "    print(f\"Original PASS:FAIL ratio = {original_ratio:.2f}:1\")\n",
        "\n",
        "    return df, pass_df, fail_df, original_ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_optimal_allocation(pass_df, fail_df, train_pct, val_pct, test_pct, original_ratio):\n",
        "    \"\"\"Find the optimal allocation that satisfies all constraints.\"\"\"\n",
        "    print(f\"\\nFinding optimal allocation for {train_pct:.1f}%/{val_pct:.1f}%/{test_pct:.1f}% split...\")\n",
        "\n",
        "    best_solution = None\n",
        "    best_score = float(\"inf\")\n",
        "\n",
        "    # Try different balanced sizes for validation and test (must be even for perfect balance)\n",
        "    max_search = min(50, len(fail_df) * 2)  # Reasonable search limit\n",
        "\n",
        "    for val_size in range(2, max_search, 2):  # Even numbers only\n",
        "        val_n_fail = val_size // 2\n",
        "        val_n_pass = val_size // 2\n",
        "\n",
        "        # Try test sizes from 2 to remaining capacity\n",
        "        max_test_fail = len(fail_df) - val_n_fail\n",
        "        for test_size in range(2, min(max_search, 2 * max_test_fail + 1), 2):  # Even numbers only\n",
        "            test_n_fail = test_size // 2\n",
        "            test_n_pass = test_size // 2\n",
        "\n",
        "            # Check if we have enough FAIL examples\n",
        "            if val_n_fail + test_n_fail > len(fail_df):\n",
        "                continue\n",
        "\n",
        "            # Calculate remaining for train\n",
        "            train_n_fail = len(fail_df) - val_n_fail - test_n_fail\n",
        "\n",
        "            # For train to be representative, use same ratio as original\n",
        "            train_n_pass_ideal = int(train_n_fail * original_ratio)\n",
        "\n",
        "            # Check if we have enough PASS examples\n",
        "            total_pass_needed = val_n_pass + test_n_pass + train_n_pass_ideal\n",
        "            if total_pass_needed > len(pass_df):\n",
        "                # Adjust train_n_pass to what's available\n",
        "                train_n_pass_actual = len(pass_df) - val_n_pass - test_n_pass\n",
        "                if train_n_pass_actual < 0:\n",
        "                    continue  # Not enough PASS examples\n",
        "            else:\n",
        "                train_n_pass_actual = train_n_pass_ideal\n",
        "\n",
        "            train_size = train_n_pass_actual + train_n_fail\n",
        "\n",
        "            # Calculate total and percentages\n",
        "            total_size = val_size + test_size + train_size\n",
        "            if total_size == 0:\n",
        "                continue\n",
        "\n",
        "            actual_train_pct = (train_size / total_size) * 100\n",
        "            actual_val_pct = (val_size / total_size) * 100\n",
        "            actual_test_pct = (test_size / total_size) * 100\n",
        "\n",
        "            # Calculate how far we are from target percentages\n",
        "            pct_diff = abs(actual_train_pct - train_pct) + abs(actual_val_pct - val_pct) + abs(actual_test_pct - test_pct)\n",
        "\n",
        "            # Check train representativeness\n",
        "            if train_n_fail > 0:\n",
        "                train_ratio = train_n_pass_actual / train_n_fail\n",
        "                ratio_preservation = abs(train_ratio - original_ratio) / original_ratio\n",
        "            else:\n",
        "                ratio_preservation = 1.0  # Bad if no FAIL in train\n",
        "\n",
        "            # Combined score: prioritize ratio preservation and target percentages\n",
        "            score = pct_diff + (ratio_preservation * 50)  # Weight ratio preservation heavily\n",
        "\n",
        "            if score < best_score and train_n_fail > 0:  # Must have some FAIL in train\n",
        "                best_score = score\n",
        "                best_solution = {\n",
        "                    \"val_n_pass\": val_n_pass,\n",
        "                    \"val_n_fail\": val_n_fail,\n",
        "                    \"test_n_pass\": test_n_pass,\n",
        "                    \"test_n_fail\": test_n_fail,\n",
        "                    \"train_n_pass\": train_n_pass_actual,\n",
        "                    \"train_n_fail\": train_n_fail,\n",
        "                    \"train_pct\": actual_train_pct,\n",
        "                    \"val_pct\": actual_val_pct,\n",
        "                    \"test_pct\": actual_test_pct,\n",
        "                    \"total_size\": total_size,\n",
        "                }\n",
        "\n",
        "    if best_solution is None:\n",
        "        print(\"âš ï¸  Could not find optimal solution, using fallback...\")\n",
        "        # Fallback: use a reasonable split\n",
        "        val_n_fail = test_n_fail = min(6, len(fail_df) // 3)\n",
        "        val_n_pass = test_n_pass = val_n_fail\n",
        "        train_n_fail = len(fail_df) - val_n_fail - test_n_fail\n",
        "        train_n_pass = min(len(pass_df) - val_n_pass - test_n_pass, int(train_n_fail * original_ratio))\n",
        "\n",
        "        best_solution = {\n",
        "            \"val_n_pass\": val_n_pass,\n",
        "            \"val_n_fail\": val_n_fail,\n",
        "            \"test_n_pass\": test_n_pass,\n",
        "            \"test_n_fail\": test_n_fail,\n",
        "            \"train_n_pass\": train_n_pass,\n",
        "            \"train_n_fail\": train_n_fail,\n",
        "        }\n",
        "    else:\n",
        "        print(f\"âœ… Found optimal solution:\")\n",
        "        print(\n",
        "            f\"   Target vs actual: {train_pct:.1f}%â†’{best_solution['train_pct']:.1f}%, {val_pct:.1f}%â†’{best_solution['val_pct']:.1f}%, {test_pct:.1f}%â†’{best_solution['test_pct']:.1f}%\"\n",
        "        )\n",
        "\n",
        "    return best_solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def allocate_examples(pass_df, fail_df, allocation, random_seed=None):\n",
        "    \"\"\"Allocate PASS and FAIL examples to train/validation/test splits.\"\"\"\n",
        "    # Extract allocation numbers\n",
        "    val_n_pass = allocation[\"val_n_pass\"]\n",
        "    val_n_fail = allocation[\"val_n_fail\"]\n",
        "    test_n_pass = allocation[\"test_n_pass\"]\n",
        "    test_n_fail = allocation[\"test_n_fail\"]\n",
        "    train_n_pass = allocation[\"train_n_pass\"]\n",
        "    train_n_fail = allocation[\"train_n_fail\"]\n",
        "\n",
        "    # Generate random seed if not provided\n",
        "    if random_seed is None:\n",
        "        random_seed = np.random.randint(0, 2**31)\n",
        "        print(f\"Using random seed: {random_seed}\")\n",
        "\n",
        "    # Shuffle examples for random distribution\n",
        "    pass_shuffled = pass_df.sample(n=len(pass_df), random_state=random_seed).reset_index(drop=True)\n",
        "    fail_shuffled = fail_df.sample(n=len(fail_df), random_state=random_seed).reset_index(drop=True)\n",
        "\n",
        "    # Allocate FAIL examples\n",
        "    fail_idx = 0\n",
        "    val_fail = fail_shuffled.iloc[fail_idx : fail_idx + val_n_fail] if val_n_fail > 0 else pd.DataFrame()\n",
        "    fail_idx += val_n_fail\n",
        "    test_fail = fail_shuffled.iloc[fail_idx : fail_idx + test_n_fail] if test_n_fail > 0 else pd.DataFrame()\n",
        "    fail_idx += test_n_fail\n",
        "    train_fail = fail_shuffled.iloc[fail_idx : fail_idx + train_n_fail] if train_n_fail > 0 else pd.DataFrame()\n",
        "\n",
        "    # Allocate PASS examples\n",
        "    pass_idx = 0\n",
        "    val_pass = pass_shuffled.iloc[pass_idx : pass_idx + val_n_pass] if val_n_pass > 0 else pd.DataFrame()\n",
        "    pass_idx += val_n_pass\n",
        "    test_pass = pass_shuffled.iloc[pass_idx : pass_idx + test_n_pass] if test_n_pass > 0 else pd.DataFrame()\n",
        "    pass_idx += test_n_pass\n",
        "    train_pass = pass_shuffled.iloc[pass_idx : pass_idx + train_n_pass] if train_n_pass > 0 else pd.DataFrame()\n",
        "\n",
        "    # Combine PASS and FAIL for each split\n",
        "    validation_df = pd.concat([val_pass, val_fail], ignore_index=True) if len(val_pass) > 0 or len(val_fail) > 0 else pd.DataFrame()\n",
        "    test_df = pd.concat([test_pass, test_fail], ignore_index=True) if len(test_pass) > 0 or len(test_fail) > 0 else pd.DataFrame()\n",
        "    train_df = pd.concat([train_pass, train_fail], ignore_index=True) if len(train_pass) > 0 or len(train_fail) > 0 else pd.DataFrame()\n",
        "\n",
        "    return train_df, validation_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify_splits(train_df, validation_df, test_df, original_ratio):\n",
        "    \"\"\"Verify the quality of the splits.\"\"\"\n",
        "    print(f\"\\nFinal splits created:\")\n",
        "    print(f\"Train: {len(train_df)} examples\")\n",
        "    print(f\"Validation: {len(validation_df)} examples\")\n",
        "    print(f\"Test: {len(test_df)} examples\")\n",
        "\n",
        "    total_used = len(train_df) + len(validation_df) + len(test_df)\n",
        "    print(f\"Total used: {total_used}\")\n",
        "\n",
        "    # Calculate final percentages\n",
        "    if total_used > 0:\n",
        "        train_pct = (len(train_df) / total_used) * 100\n",
        "        val_pct = (len(validation_df) / total_used) * 100\n",
        "        test_pct = (len(test_df) / total_used) * 100\n",
        "\n",
        "        print(f\"\\nFinal percentages:\")\n",
        "        print(f\"Train: {train_pct:.1f}%\")\n",
        "        print(f\"Validation: {val_pct:.1f}%\")\n",
        "        print(f\"Test: {test_pct:.1f}%\")\n",
        "\n",
        "    # Verify balance\n",
        "    print(f\"\\nBalance verification:\")\n",
        "\n",
        "    if len(validation_df) > 0:\n",
        "        val_pass = len(validation_df[validation_df[\"label\"] == \"PASS\"])\n",
        "        val_fail = len(validation_df[validation_df[\"label\"] == \"FAIL\"])\n",
        "        print(f\"Validation: {val_pass} PASS = {val_fail} FAIL âœ“\")\n",
        "\n",
        "    if len(test_df) > 0:\n",
        "        test_pass = len(test_df[test_df[\"label\"] == \"PASS\"])\n",
        "        test_fail = len(test_df[test_df[\"label\"] == \"FAIL\"])\n",
        "        print(f\"Test: {test_pass} PASS = {test_fail} FAIL âœ“\")\n",
        "\n",
        "    if len(train_df) > 0:\n",
        "        train_pass = len(train_df[train_df[\"label\"] == \"PASS\"])\n",
        "        train_fail = len(train_df[train_df[\"label\"] == \"FAIL\"])\n",
        "        train_ratio = train_pass / train_fail if train_fail > 0 else float(\"inf\")\n",
        "\n",
        "        print(f\"Train: {train_pass} PASS + {train_fail} FAIL (ratio: {train_ratio:.2f}:1)\")\n",
        "        print(f\"   Original ratio: {original_ratio:.2f}:1\")\n",
        "        print(f\"   Ratio preservation: {(train_ratio / original_ratio) * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_proportional_splits(csv_path, train_pct=15.0, val_pct=40.0, test_pct=45.0, output_path=None, random_seed=None):\n",
        "    \"\"\"\n",
        "    Create proportional train/validation/test splits from labeled traces data using ALL the data.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): Path to the CSV file with labeled traces\n",
        "        train_pct (float): Target percentage for training set (default: 15.0)\n",
        "        val_pct (float): Target percentage for validation set (default: 40.0)\n",
        "        test_pct (float): Target percentage for test set (default: 45.0)\n",
        "        output_path (str): Path to save the combined dataset (optional)\n",
        "        random_seed (int): Random seed for reproducible splits (default: None for random)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_df, validation_df, test_df, combined_df)\n",
        "\n",
        "    Requirements:\n",
        "        - Uses ALL the data from the CSV file\n",
        "        - Maintains the same PASS/FAIL proportion across all three datasets\n",
        "        - Splits according to specified percentages\n",
        "        - Randomized allocation for reproducible results when seed is provided\n",
        "    \"\"\"\n",
        "\n",
        "    # Validate percentages\n",
        "    if abs(train_pct + val_pct + test_pct - 100.0) > 1e-10:\n",
        "        raise ValueError(\"Percentages must sum to 100%\")\n",
        "\n",
        "    print(f\"Creating proportional splits with {train_pct:.1f}%/{val_pct:.1f}%/{test_pct:.1f}% distribution using ALL data\")\n",
        "\n",
        "    # Load data\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Loaded dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
        "\n",
        "    # Check the distribution of labels\n",
        "    label_counts = df[\"label\"].value_counts()\n",
        "    print(f\"\\nOriginal label distribution:\")\n",
        "    print(label_counts)\n",
        "\n",
        "    pass_df = df[df[\"label\"] == \"PASS\"].reset_index(drop=True)\n",
        "    fail_df = df[df[\"label\"] == \"FAIL\"].reset_index(drop=True)\n",
        "\n",
        "    total_pass = len(pass_df)\n",
        "    total_fail = len(fail_df)\n",
        "    original_ratio = total_pass / total_fail if total_fail > 0 else float(\"inf\")\n",
        "\n",
        "    print(f\"Total PASS: {total_pass}, Total FAIL: {total_fail}\")\n",
        "    print(f\"Original PASS:FAIL ratio = {original_ratio:.2f}:1\")\n",
        "\n",
        "    # Set random seed if provided\n",
        "    if random_seed is not None:\n",
        "        np.random.seed(random_seed)\n",
        "        print(f\"Using random seed: {random_seed}\")\n",
        "    else:\n",
        "        random_seed = np.random.randint(0, 2**31)\n",
        "        print(f\"Using random seed: {random_seed}\")\n",
        "\n",
        "    # Shuffle the data\n",
        "    pass_shuffled = pass_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "    fail_shuffled = fail_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split sizes for PASS examples\n",
        "    train_pass_size = int(np.round(total_pass * train_pct / 100))\n",
        "    val_pass_size = int(np.round(total_pass * val_pct / 100))\n",
        "    test_pass_size = total_pass - train_pass_size - val_pass_size  # Use remaining to ensure we use all data\n",
        "\n",
        "    # Calculate split sizes for FAIL examples\n",
        "    train_fail_size = int(np.round(total_fail * train_pct / 100))\n",
        "    val_fail_size = int(np.round(total_fail * val_pct / 100))\n",
        "    test_fail_size = total_fail - train_fail_size - val_fail_size  # Use remaining to ensure we use all data\n",
        "\n",
        "    print(f\"\\nSplit allocation:\")\n",
        "    print(f\"Train: {train_pass_size} PASS + {train_fail_size} FAIL = {train_pass_size + train_fail_size} total\")\n",
        "    print(f\"Validation: {val_pass_size} PASS + {val_fail_size} FAIL = {val_pass_size + val_fail_size} total\")\n",
        "    print(f\"Test: {test_pass_size} PASS + {test_fail_size} FAIL = {test_pass_size + test_fail_size} total\")\n",
        "    print(\n",
        "        f\"Total: {train_pass_size + val_pass_size + test_pass_size} PASS + {train_fail_size + val_fail_size + test_fail_size} FAIL = {len(df)} total\"\n",
        "    )\n",
        "\n",
        "    # Split PASS examples\n",
        "    train_pass = pass_shuffled.iloc[:train_pass_size].copy()\n",
        "    val_pass = pass_shuffled.iloc[train_pass_size : train_pass_size + val_pass_size].copy()\n",
        "    test_pass = pass_shuffled.iloc[train_pass_size + val_pass_size :].copy()\n",
        "\n",
        "    # Split FAIL examples\n",
        "    train_fail = fail_shuffled.iloc[:train_fail_size].copy()\n",
        "    val_fail = fail_shuffled.iloc[train_fail_size : train_fail_size + val_fail_size].copy()\n",
        "    test_fail = fail_shuffled.iloc[train_fail_size + val_fail_size :].copy()\n",
        "\n",
        "    # Combine PASS and FAIL for each split\n",
        "    train_df = pd.concat([train_pass, train_fail], ignore_index=True)\n",
        "    validation_df = pd.concat([val_pass, val_fail], ignore_index=True)\n",
        "    test_df = pd.concat([test_pass, test_fail], ignore_index=True)\n",
        "\n",
        "    # Add dataset labels\n",
        "    train_df = train_df.copy()\n",
        "    validation_df = validation_df.copy()\n",
        "    test_df = test_df.copy()\n",
        "\n",
        "    train_df[\"dataset\"] = \"train\"\n",
        "    validation_df[\"dataset\"] = \"validation\"\n",
        "    test_df[\"dataset\"] = \"test\"\n",
        "\n",
        "    # Verify proportions\n",
        "    print(f\"\\nFinal proportions verification:\")\n",
        "    for name, dataset in [(\"Train\", train_df), (\"Validation\", validation_df), (\"Test\", test_df)]:\n",
        "        pass_count = len(dataset[dataset[\"label\"] == \"PASS\"])\n",
        "        fail_count = len(dataset[dataset[\"label\"] == \"FAIL\"])\n",
        "        total_count = len(dataset)\n",
        "        pass_prop = pass_count / total_count * 100 if total_count > 0 else 0\n",
        "        fail_prop = fail_count / total_count * 100 if total_count > 0 else 0\n",
        "        ratio = pass_count / fail_count if fail_count > 0 else float(\"inf\")\n",
        "\n",
        "        print(f\"{name}: {pass_count} PASS ({pass_prop:.1f}%) + {fail_count} FAIL ({fail_prop:.1f}%) = {total_count} total\")\n",
        "        print(f\"  {name} PASS:FAIL ratio = {ratio:.2f}:1\")\n",
        "\n",
        "    # Check that proportions are maintained\n",
        "    train_ratio = len(train_df[train_df[\"label\"] == \"PASS\"]) / len(train_df[train_df[\"label\"] == \"FAIL\"])\n",
        "    val_ratio = len(validation_df[validation_df[\"label\"] == \"PASS\"]) / len(validation_df[validation_df[\"label\"] == \"FAIL\"])\n",
        "    test_ratio = len(test_df[test_df[\"label\"] == \"PASS\"]) / len(test_df[test_df[\"label\"] == \"FAIL\"])\n",
        "\n",
        "    print(f\"\\nRatio consistency check:\")\n",
        "    print(f\"Original ratio: {original_ratio:.3f}:1\")\n",
        "    print(f\"Train ratio: {train_ratio:.3f}:1 (diff: {abs(train_ratio - original_ratio) / original_ratio * 100:.1f}%)\")\n",
        "    print(f\"Validation ratio: {val_ratio:.3f}:1 (diff: {abs(val_ratio - original_ratio) / original_ratio * 100:.1f}%)\")\n",
        "    print(f\"Test ratio: {test_ratio:.3f}:1 (diff: {abs(test_ratio - original_ratio) / original_ratio * 100:.1f}%)\")\n",
        "\n",
        "    # Combine datasets\n",
        "    combined_df = pd.concat([train_df, validation_df, test_df], ignore_index=True)\n",
        "\n",
        "    # Save if output path provided\n",
        "    if output_path:\n",
        "        combined_df.to_csv(output_path, index=False)\n",
        "        print(f\"\\nğŸ’¾ Saved combined dataset to: {output_path}\")\n",
        "\n",
        "    print(f\"\\nğŸ‰ Successfully created proportional splits using ALL {len(df)} examples!\")\n",
        "\n",
        "    return train_df, validation_df, test_df, combined_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage with the current data using ALL the data\n",
        "train_df, validation_df, test_df, combined_df = create_proportional_splits(\n",
        "    csv_path=\"data/labeled_traces.csv\",\n",
        "    train_pct=20.0,\n",
        "    val_pct=40.0,\n",
        "    test_pct=40.0,\n",
        "    output_path=\"data/labeled_traces_dataset.csv\",\n",
        "    random_seed=42,  # Fixed seed for reproducible results\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "USAGE EXAMPLES:\n",
            "============================================================\n",
            "\n",
            "1. Reproducible split with fixed seed:\n",
            "Creating proportional splits with 20.0%/35.0%/45.0% distribution using ALL data\n",
            "Loaded dataset with 101 rows and 11 columns\n",
            "\n",
            "Original label distribution:\n",
            "label\n",
            "PASS    75\n",
            "FAIL    26\n",
            "Name: count, dtype: int64\n",
            "Total PASS: 75, Total FAIL: 26\n",
            "Original PASS:FAIL ratio = 2.88:1\n",
            "Using random seed: 123\n",
            "\n",
            "Split allocation:\n",
            "Train: 15 PASS + 5 FAIL = 20 total\n",
            "Validation: 26 PASS + 9 FAIL = 35 total\n",
            "Test: 34 PASS + 12 FAIL = 46 total\n",
            "Total: 75 PASS + 26 FAIL = 101 total\n",
            "\n",
            "Final proportions verification:\n",
            "Train: 15 PASS (75.0%) + 5 FAIL (25.0%) = 20 total\n",
            "  Train PASS:FAIL ratio = 3.00:1\n",
            "Validation: 26 PASS (74.3%) + 9 FAIL (25.7%) = 35 total\n",
            "  Validation PASS:FAIL ratio = 2.89:1\n",
            "Test: 34 PASS (73.9%) + 12 FAIL (26.1%) = 46 total\n",
            "  Test PASS:FAIL ratio = 2.83:1\n",
            "\n",
            "Ratio consistency check:\n",
            "Original ratio: 2.885:1\n",
            "Train ratio: 3.000:1 (diff: 4.0%)\n",
            "Validation ratio: 2.889:1 (diff: 0.1%)\n",
            "Test ratio: 2.833:1 (diff: 1.8%)\n",
            "\n",
            "ğŸ‰ Successfully created proportional splits using ALL 101 examples!\n",
            "\n",
            "========================================\n",
            "2. Random split (will be different each run):\n",
            "Creating proportional splits with 20.0%/35.0%/45.0% distribution using ALL data\n",
            "Loaded dataset with 101 rows and 11 columns\n",
            "\n",
            "Original label distribution:\n",
            "label\n",
            "PASS    75\n",
            "FAIL    26\n",
            "Name: count, dtype: int64\n",
            "Total PASS: 75, Total FAIL: 26\n",
            "Original PASS:FAIL ratio = 2.88:1\n",
            "Using random seed: 456\n",
            "\n",
            "Split allocation:\n",
            "Train: 15 PASS + 5 FAIL = 20 total\n",
            "Validation: 26 PASS + 9 FAIL = 35 total\n",
            "Test: 34 PASS + 12 FAIL = 46 total\n",
            "Total: 75 PASS + 26 FAIL = 101 total\n",
            "\n",
            "Final proportions verification:\n",
            "Train: 15 PASS (75.0%) + 5 FAIL (25.0%) = 20 total\n",
            "  Train PASS:FAIL ratio = 3.00:1\n",
            "Validation: 26 PASS (74.3%) + 9 FAIL (25.7%) = 35 total\n",
            "  Validation PASS:FAIL ratio = 2.89:1\n",
            "Test: 34 PASS (73.9%) + 12 FAIL (26.1%) = 46 total\n",
            "  Test PASS:FAIL ratio = 2.83:1\n",
            "\n",
            "Ratio consistency check:\n",
            "Original ratio: 2.885:1\n",
            "Train ratio: 3.000:1 (diff: 4.0%)\n",
            "Validation ratio: 2.889:1 (diff: 0.1%)\n",
            "Test ratio: 2.833:1 (diff: 1.8%)\n",
            "\n",
            "ğŸ‰ Successfully created proportional splits using ALL 101 examples!\n",
            "\n",
            "========================================\n",
            "3. Another random split (different from above):\n",
            "Creating proportional splits with 20.0%/35.0%/45.0% distribution using ALL data\n",
            "Loaded dataset with 101 rows and 11 columns\n",
            "\n",
            "Original label distribution:\n",
            "label\n",
            "PASS    75\n",
            "FAIL    26\n",
            "Name: count, dtype: int64\n",
            "Total PASS: 75, Total FAIL: 26\n",
            "Original PASS:FAIL ratio = 2.88:1\n",
            "Using random seed: 789\n",
            "\n",
            "Split allocation:\n",
            "Train: 15 PASS + 5 FAIL = 20 total\n",
            "Validation: 26 PASS + 9 FAIL = 35 total\n",
            "Test: 34 PASS + 12 FAIL = 46 total\n",
            "Total: 75 PASS + 26 FAIL = 101 total\n",
            "\n",
            "Final proportions verification:\n",
            "Train: 15 PASS (75.0%) + 5 FAIL (25.0%) = 20 total\n",
            "  Train PASS:FAIL ratio = 3.00:1\n",
            "Validation: 26 PASS (74.3%) + 9 FAIL (25.7%) = 35 total\n",
            "  Validation PASS:FAIL ratio = 2.89:1\n",
            "Test: 34 PASS (73.9%) + 12 FAIL (26.1%) = 46 total\n",
            "  Test PASS:FAIL ratio = 2.83:1\n",
            "\n",
            "Ratio consistency check:\n",
            "Original ratio: 2.885:1\n",
            "Train ratio: 3.000:1 (diff: 4.0%)\n",
            "Validation ratio: 2.889:1 (diff: 0.1%)\n",
            "Test ratio: 2.833:1 (diff: 1.8%)\n",
            "\n",
            "ğŸ‰ Successfully created proportional splits using ALL 101 examples!\n",
            "\n",
            "========================================\n",
            "RANDOMIZATION VERIFICATION:\n",
            "========================================\n",
            "Train set overlap between random runs: 4/20 (20.0%)\n",
            "âœ… Randomization working!\n",
            "\n",
            "ğŸ’¡ TIP: Use random_seed=42 (or any number) for reproducible splits\n",
            "ğŸ’¡ TIP: Use random_seed=None for different splits each time\n"
          ]
        }
      ],
      "source": [
        "# Example usage variations:\n",
        "print(\"=\" * 60)\n",
        "print(\"USAGE EXAMPLES:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Reproducible splits (same examples each time)\n",
        "print(\"\\n1. Reproducible split with fixed seed:\")\n",
        "train1, val1, test1, _ = create_proportional_splits(\n",
        "    csv_path=\"data/labeled_traces.csv\",\n",
        "    train_pct=20.0,\n",
        "    val_pct=35.0,\n",
        "    test_pct=45.0,\n",
        "    random_seed=123,  # Fixed seed for reproducibility\n",
        ")\n",
        "\n",
        "# 2. Different random splits (different examples each time)\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"2. Random split (will be different each run):\")\n",
        "train2, val2, test2, _ = create_proportional_splits(\n",
        "    csv_path=\"data/labeled_traces.csv\",\n",
        "    train_pct=20.0,\n",
        "    val_pct=35.0,\n",
        "    test_pct=45.0,\n",
        "    random_seed=456,  # Different seed\n",
        ")\n",
        "\n",
        "# 3. Another random split to show difference\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"3. Another random split (different from above):\")\n",
        "train3, val3, test3, _ = create_proportional_splits(\n",
        "    csv_path=\"data/labeled_traces.csv\",\n",
        "    train_pct=20.0,\n",
        "    val_pct=35.0,\n",
        "    test_pct=45.0,\n",
        "    random_seed=789,  # Different random seed\n",
        ")\n",
        "\n",
        "# Show that the examples are different across random runs\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"RANDOMIZATION VERIFICATION:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if len(train2) > 0 and len(train3) > 0:\n",
        "    # Check if train sets have different examples by comparing trace_ids\n",
        "    train2_ids = set(train2[\"trace_id\"].tolist()) if \"trace_id\" in train2.columns else set(train2.index.tolist())\n",
        "    train3_ids = set(train3[\"trace_id\"].tolist()) if \"trace_id\" in train3.columns else set(train3.index.tolist())\n",
        "    overlap = len(train2_ids.intersection(train3_ids))\n",
        "    total = len(train2_ids)\n",
        "\n",
        "    print(f\"Train set overlap between random runs: {overlap}/{total} ({overlap / total * 100:.1f}%)\")\n",
        "    print(f\"âœ… Randomization working!\" if overlap < total else \"âš ï¸  Same examples - check randomization\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ TIP: Use random_seed=42 (or any number) for reproducible splits\")\n",
        "print(f\"ğŸ’¡ TIP: Use random_seed=None for different splits each time\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Checking balance across splits:\n",
            "\n",
            "Original - Label distribution:\n",
            "PASS: 75 (74.3%)\n",
            "FAIL: 26 (25.7%)\n",
            "Balance ratio (PASS:FAIL): 75:26\n",
            "Balance score: 2.88 (1.0 = perfect balance)\n",
            "\n",
            "Train - Label distribution:\n",
            "PASS: 15 (75.0%)\n",
            "FAIL: 5 (25.0%)\n",
            "Balance ratio (PASS:FAIL): 15:5\n",
            "Balance score: 3.00 (1.0 = perfect balance)\n",
            "\n",
            "Validation - Label distribution:\n",
            "PASS: 30 (75.0%)\n",
            "FAIL: 10 (25.0%)\n",
            "Balance ratio (PASS:FAIL): 30:10\n",
            "Balance score: 3.00 (1.0 = perfect balance)\n",
            "\n",
            "Test - Label distribution:\n",
            "PASS: 30 (73.2%)\n",
            "FAIL: 11 (26.8%)\n",
            "Balance ratio (PASS:FAIL): 30:11\n",
            "Balance score: 2.73 (1.0 = perfect balance)\n"
          ]
        }
      ],
      "source": [
        "# Verify balance - check label proportions in each split\n",
        "def check_balance(dataset_name, dataset_df):\n",
        "    if len(dataset_df) == 0:\n",
        "        print(f\"\\n{dataset_name} - EMPTY DATASET\")\n",
        "        return\n",
        "\n",
        "    label_counts = dataset_df[\"label\"].value_counts()\n",
        "    label_props = label_counts / len(dataset_df)\n",
        "\n",
        "    pass_count = label_counts.get(\"PASS\", 0)\n",
        "    fail_count = label_counts.get(\"FAIL\", 0)\n",
        "    pass_prop = label_props.get(\"PASS\", 0)\n",
        "    fail_prop = label_props.get(\"FAIL\", 0)\n",
        "\n",
        "    print(f\"\\n{dataset_name} - Label distribution:\")\n",
        "    print(f\"PASS: {pass_count} ({pass_prop:.1%})\")\n",
        "    print(f\"FAIL: {fail_count} ({fail_prop:.1%})\")\n",
        "    print(f\"Balance ratio (PASS:FAIL): {pass_count}:{fail_count}\")\n",
        "\n",
        "    if pass_count > 0 and fail_count > 0:\n",
        "        ratio = max(pass_count, fail_count) / min(pass_count, fail_count)\n",
        "        print(f\"Balance score: {ratio:.2f} (1.0 = perfect balance)\")\n",
        "        if ratio == 1.0:\n",
        "            print(\"ğŸ¯ PERFECTLY BALANCED!\")\n",
        "    elif pass_count > 0 and fail_count == 0:\n",
        "        print(\"âš ï¸  Only PASS examples (imbalanced)\")\n",
        "    elif fail_count > 0 and pass_count == 0:\n",
        "        print(\"âš ï¸  Only FAIL examples (imbalanced)\")\n",
        "\n",
        "    return label_props\n",
        "\n",
        "\n",
        "print(\"ğŸ” Checking balance across splits:\")\n",
        "original_props = check_balance(\"Original\", df)\n",
        "train_props = check_balance(\"Train\", train_df)\n",
        "val_props = check_balance(\"Validation\", validation_df)\n",
        "test_props = check_balance(\"Test\", test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Added 'dataset' column to each split:\n",
            "Train dataset column: train\n",
            "Validation dataset column: validation\n",
            "Test dataset column: test\n"
          ]
        }
      ],
      "source": [
        "# Add dataset column to each split\n",
        "train_df = train_df.copy()\n",
        "validation_df = validation_df.copy()\n",
        "test_df = test_df.copy()\n",
        "\n",
        "train_df[\"dataset\"] = \"train\"\n",
        "validation_df[\"dataset\"] = \"validation\"\n",
        "test_df[\"dataset\"] = \"test\"\n",
        "\n",
        "print(\"âœ… Added 'dataset' column to each split:\")\n",
        "print(f\"Train dataset column: {train_df['dataset'].iloc[0] if len(train_df) > 0 else 'N/A'}\")\n",
        "print(f\"Validation dataset column: {validation_df['dataset'].iloc[0] if len(validation_df) > 0 else 'N/A'}\")\n",
        "print(f\"Test dataset column: {test_df['dataset'].iloc[0] if len(test_df) > 0 else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Combined dataset shape: (101, 12)\n",
            "ğŸ“Š Original dataset shape: (101, 11)\n",
            "\n",
            "ğŸ“ˆ Dataset counts:\n",
            "dataset\n",
            "test          41\n",
            "train         20\n",
            "validation    40\n",
            "dtype: int64\n",
            "\n",
            "ğŸ·ï¸ Label distribution by dataset:\n",
            "label       FAIL  PASS\n",
            "dataset               \n",
            "test          11    30\n",
            "train          5    15\n",
            "validation    10    30\n",
            "\n",
            "ğŸ“Š Dataset percentages:\n",
            "test: 41 (40.6%)\n",
            "train: 20 (19.8%)\n",
            "validation: 40 (39.6%)\n",
            "\n",
            "ğŸ¯ Balance Achievement Summary:\n",
            "Validation: 30 PASS = 10 FAIL âœ“ Perfect Balance!\n",
            "Test: 30 PASS = 11 FAIL âœ“ Perfect Balance!\n"
          ]
        }
      ],
      "source": [
        "# Combine the 3 datasets back together\n",
        "combined_df = pd.concat([train_df, validation_df, test_df], ignore_index=True)\n",
        "\n",
        "print(f\"ğŸ“Š Combined dataset shape: {combined_df.shape}\")\n",
        "print(f\"ğŸ“Š Original dataset shape: {df.shape}\")\n",
        "\n",
        "# Verify the counts by grouping on \"dataset\"\n",
        "dataset_counts = combined_df.groupby(\"dataset\").size()\n",
        "print(f\"\\nğŸ“ˆ Dataset counts:\")\n",
        "print(dataset_counts)\n",
        "\n",
        "# Show label distribution within each dataset\n",
        "dataset_label_counts = combined_df.groupby([\"dataset\", \"label\"]).size().unstack(fill_value=0)\n",
        "print(f\"\\nğŸ·ï¸ Label distribution by dataset:\")\n",
        "print(dataset_label_counts)\n",
        "\n",
        "# Calculate percentages\n",
        "total_rows = len(combined_df)\n",
        "print(f\"\\nğŸ“Š Dataset percentages:\")\n",
        "for dataset, count in dataset_counts.items():\n",
        "    print(f\"{dataset}: {count} ({count / total_rows:.1%})\")\n",
        "\n",
        "# Highlight the perfect balance achievement\n",
        "print(f\"\\nğŸ¯ Balance Achievement Summary:\")\n",
        "val_pass = len(combined_df[(combined_df[\"dataset\"] == \"validation\") & (combined_df[\"label\"] == \"PASS\")])\n",
        "val_fail = len(combined_df[(combined_df[\"dataset\"] == \"validation\") & (combined_df[\"label\"] == \"FAIL\")])\n",
        "test_pass = len(combined_df[(combined_df[\"dataset\"] == \"test\") & (combined_df[\"label\"] == \"PASS\")])\n",
        "test_fail = len(combined_df[(combined_df[\"dataset\"] == \"test\") & (combined_df[\"label\"] == \"FAIL\")])\n",
        "\n",
        "print(f\"Validation: {val_pass} PASS = {val_fail} FAIL âœ“ Perfect Balance!\")\n",
        "print(f\"Test: {test_pass} PASS = {test_fail} FAIL âœ“ Perfect Balance!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ’¾ Saved combined dataset to: data/labeled_traces_dataset.csv\n",
            "âœ… Verification - saved file shape: (101, 12)\n",
            "âœ… Verification - dataset column unique values: ['test', 'train', 'validation']\n",
            "ğŸ“ Saved to: data/labeled_traces_dataset.csv\n",
            "\n",
            "ğŸ“Š Total rows: 101\n",
            "ğŸ”„ Train: 20 rows (19.8%) - 15 PASS:5 FAIL - âŒ IMBALANCED\n",
            "ğŸ”„ Validation: 40 rows (39.6%) - 30 PASS:10 FAIL - âŒ IMBALANCED\n",
            "ğŸ”„ Test: 41 rows (40.6%) - 30 PASS:11 FAIL - âŒ IMBALANCED\n"
          ]
        }
      ],
      "source": [
        "# Save the combined dataset\n",
        "output_path = \"data/labeled_traces_dataset.csv\"\n",
        "combined_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"ğŸ’¾ Saved combined dataset to: {output_path}\")\n",
        "\n",
        "# Verify the saved file\n",
        "saved_df = pd.read_csv(output_path)\n",
        "print(f\"âœ… Verification - saved file shape: {saved_df.shape}\")\n",
        "print(f\"âœ… Verification - dataset column unique values: {sorted(saved_df['dataset'].unique())}\")\n",
        "\n",
        "\n",
        "print(f\"ğŸ“ Saved to: {output_path}\")\n",
        "print(\"\")\n",
        "print(f\"ğŸ“Š Total rows: {len(saved_df)}\")\n",
        "\n",
        "# Final summary with balance status\n",
        "for dataset_name in [\"train\", \"validation\", \"test\"]:\n",
        "    subset = saved_df[saved_df[\"dataset\"] == dataset_name]\n",
        "    pass_count = len(subset[subset[\"label\"] == \"PASS\"])\n",
        "    fail_count = len(subset[subset[\"label\"] == \"FAIL\"])\n",
        "    percentage = len(subset) / len(saved_df) * 100\n",
        "\n",
        "    if dataset_name in [\"validation\", \"test\", \"train\"]:\n",
        "        balance_status = \"ğŸ¯ PERFECT BALANCE\" if pass_count == fail_count else \"âŒ IMBALANCED\"\n",
        "\n",
        "    print(f\"ğŸ”„ {dataset_name.title()}: {len(subset)} rows ({percentage:.1f}%) - {pass_count} PASS:{fail_count} FAIL - {balance_status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Develop Your LLM-as-Judge Prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Watch to walk-through video for HW3 where we go over how to use Loop to align our LLM judge with human annotations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Refine & Validate Your Judge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_experiment_results(experiment_id: str):\n",
        "    cursor = None\n",
        "    while True:\n",
        "        response = requests.post(\n",
        "            \"https://api.braintrust.dev/btql\",\n",
        "            json={\n",
        "                \"query\": f\"\"\"select: input, output, metadata\n",
        "from:experiment ('{experiment_id}')\n",
        "filter: scores is not null\"\"\"\n",
        "                + (f\" | cursor: '{cursor}'\" if cursor else \"\"),\n",
        "                \"use_brainstore\": True,\n",
        "                \"brainstore_realtime\": True,  # Include the latest realtime data, but a bit slower.\n",
        "            },\n",
        "            headers={\n",
        "                # Substitute your API key here\n",
        "                \"Authorization\": \"Bearer \" + os.environ[\"BRAINTRUST_API_KEY\"],\n",
        "            },\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        response_json = response.json()\n",
        "        data = response_json.get(\"data\", [])\n",
        "        cursor = response_json.get(\"cursor\")\n",
        "\n",
        "        return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': {'expected': \"Certainly! Here's a delicious and portable Paleo breakfast recipe perfect for your commute: **Sweet Potato and Egg Muffin Cups**. These are easy to prepare ahead of time, packed with nutrients, and convenient to eat on the go.\\n\\n### Sweet Potato and Egg Muffin Cups (Serves 2)\\n\\n#### Ingredients:\\n- 2 medium sweet potatoes\\n- 4 large eggs\\n- 1/2 teaspoon salt\\n- 1/4 teaspoon black pepper\\n- Optional: chopped herbs (like parsley or chives), chopped veggies (like bell peppers or spinach), or cooked bacon bits for extra flavor\\n\\n#### Instructions:\\n\\n1. **Preheat the oven:** Set your oven to 375Â°F (190Â°C). Line a muffin tin with silicone liners or lightly grease it with coconut oil to prevent sticking.\\n\\n2. **Prepare sweet potatoes:** Wash and peel the sweet potatoes. Use a grater or a food processor with a grating attachment to shred the sweet potatoes into small, fine pieces.\\n\\n3. **Squeeze out moisture:** Place the grated sweet potatoes in a clean kitchen towel or cheesecloth and squeeze out excess moisture. This helps keep the muffins from becoming too watery.\\n\\n4. **Fill the muffin cups:** Divide the shredded sweet potatoes evenly among the muffin cups, pressing them down slightly to form a base that lines the bottom and sides of each cup.\\n\\n5. **Add eggs:** In a bowl, beat the eggs with salt, pepper, and any optional herbs or veggies you'd like. Pour the beaten eggs over the sweet potato layers in each muffin cup, filling about 3/4 full.\\n\\n6. **Bake:** Place the muffin tin in the preheated oven. Bake for 20-25 minutes, or until the eggs are set and the edges are slightly golden.\\n\\n7. **Cool and store:** Let the muffin cups cool for a few minutes. Remove from the tin and place in an airtight container. These store well in the fridge for up to 3 days.\\n\\n#### To serve:\\nPack these muffin cups in a portable container, and they're ready to eat directly from your hand or with a quick grab-and-go heating in a microwave if available.\\n\\nEnjoy your nutritious and filling Paleo breakfast on your commute!\",\n",
              "  'input': 'Paleo breakfast that I can eat in the car on my commute',\n",
              "  'metadata': {'confidence': 'HIGH',\n",
              "   'dataset': 'train',\n",
              "   'dietary_restriction': 'paleo',\n",
              "   'error': None,\n",
              "   'label': 'PASS',\n",
              "   'labeled': 'True',\n",
              "   'query_id': 35,\n",
              "   'reasoning': 'The recipe for Sweet Potato and Egg Muffin Cups adheres to the Paleo dietary restriction. The ingredients used, such as sweet potatoes, eggs, salt, pepper, and optional herbs or vegetables, are all compliant with the Paleo diet, which excludes grains, legumes, dairy, refined sugar, and processed foods. The preparation method involves baking, which is suitable for Paleo. The optional addition of cooked bacon bits is also acceptable within the Paleo framework, as long as the bacon is free from non-Paleo additives like sugar or nitrates.',\n",
              "   'success': 'True',\n",
              "   'trace_id': '35_15'},\n",
              "  'output': \"Certainly! Here's a delicious and portable Paleo breakfast recipe perfect for your commute: **Sweet Potato and Egg Muffin Cups**. These are easy to prepare ahead of time, packed with nutrients, and convenient to eat on the go.\\n\\n### Sweet Potato and Egg Muffin Cups (Serves 2)\\n\\n#### Ingredients:\\n- 2 medium sweet potatoes\\n- 4 large eggs\\n- 1/2 teaspoon salt\\n- 1/4 teaspoon black pepper\\n- Optional: chopped herbs (like parsley or chives), chopped veggies (like bell peppers or spinach), or cooked bacon bits for extra flavor\\n\\n#### Instructions:\\n\\n1. **Preheat the oven:** Set your oven to 375Â°F (190Â°C). Line a muffin tin with silicone liners or lightly grease it with coconut oil to prevent sticking.\\n\\n2. **Prepare sweet potatoes:** Wash and peel the sweet potatoes. Use a grater or a food processor with a grating attachment to shred the sweet potatoes into small, fine pieces.\\n\\n3. **Squeeze out moisture:** Place the grated sweet potatoes in a clean kitchen towel or cheesecloth and squeeze out excess moisture. This helps keep the muffins from becoming too watery.\\n\\n4. **Fill the muffin cups:** Divide the shredded sweet potatoes evenly among the muffin cups, pressing them down slightly to form a base that lines the bottom and sides of each cup.\\n\\n5. **Add eggs:** In a bowl, beat the eggs with salt, pepper, and any optional herbs or veggies you'd like. Pour the beaten eggs over the sweet potato layers in each muffin cup, filling about 3/4 full.\\n\\n6. **Bake:** Place the muffin tin in the preheated oven. Bake for 20-25 minutes, or until the eggs are set and the edges are slightly golden.\\n\\n7. **Cool and store:** Let the muffin cups cool for a few minutes. Remove from the tin and place in an airtight container. These store well in the fridge for up to 3 days.\\n\\n#### To serve:\\nPack these muffin cups in a portable container, and they're ready to eat directly from your hand or with a quick grab-and-go heating in a microwave if available.\\n\\nEnjoy your nutritious and filling Paleo breakfast on your commute!\"},\n",
              " 'metadata': {'choice': 'PASS',\n",
              "  'rationale': \"Let me evaluate this recipe step by step against the strict Paleo dietary requirements:\\n\\n1. Sweet Potatoes:\\n- Allowed on Paleo diet\\n- Natural, unprocessed whole food\\n- Root vegetable that's a Paleo-approved carb source\\n\\n2. Eggs:\\n- Allowed on Paleo diet\\n- High-quality protein source\\n- Minimally processed whole food\\n\\n3. Salt and Black Pepper:\\n- Natural seasonings allowed on Paleo\\n- No artificial additives\\n\\n4. Optional Add-ins mentioned:\\n- Herbs (parsley, chives) - Allowed on Paleo\\n- Vegetables (bell peppers, spinach) - Allowed on Paleo\\n- Bacon (assuming plain, uncured) - Allowed on Paleo if uncured and without added sugars/preservatives\\n\\n5. Cooking Methods/Additional Ingredients:\\n- Coconut oil for greasing - Allowed on Paleo\\n- Silicone liners - Not an ingredient, just a cooking tool\\n- No grains, legumes, dairy, refined sugars, or processed foods used\\n\\n6. Storage Method:\\n- Simple refrigeration in container\\n- No preservatives or processing involved\\n\\nAll ingredients align with Paleo guidelines. There are no:\\n- Grains\\n- Legumes\\n- Dairy products\\n- Refined sugars\\n- Processed foods\\n- Artificial preservatives or additives\"},\n",
              " 'output': {'score': 1}}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_results = get_experiment_results(\"39ea08f0-bd26-4b59-9190-76f78ac2731b\")\n",
        "\n",
        "print(len(experiment_results))\n",
        "experiment_results[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of experiment results: 101\n",
            "Sample result structure:\n",
            "Keys: ['input', 'metadata', 'output']\n",
            "Metadata keys: ['choice', 'rationale']\n",
            "Output keys: ['score']\n",
            "Sample result: {'input': {'expected': \"Certainly! Here's a delicious and portable Paleo breakfast recipe perfect for your commute: **Sweet Potato and Egg Muffin Cups**. These are easy to prepare ahead of time, packed with nutrients, and convenient to eat on the go.\\n\\n### Sweet Potato and Egg Muffin Cups (Serves 2)\\n\\n#### Ingredients:\\n- 2 medium sweet potatoes\\n- 4 large eggs\\n- 1/2 teaspoon salt\\n- 1/4 teaspoon black pepper\\n- Optional: chopped herbs (like parsley or chives), chopped veggies (like bell peppers or spinach), or cooked bacon bits for extra flavor\\n\\n#### Instructions:\\n\\n1. **Preheat the oven:** Set your oven to 375Â°F (190Â°C). Line a muffin tin with silicone liners or lightly grease it with coconut oil to prevent sticking.\\n\\n2. **Prepare sweet potatoes:** Wash and peel the sweet potatoes. Use a grater or a food processor with a grating attachment to shred the sweet potatoes into small, fine pieces.\\n\\n3. **Squeeze out moisture:** Place the grated sweet potatoes in a clean kitchen towel or cheesecloth and squeeze out excess moisture. This helps keep the muffins from becoming too watery.\\n\\n4. **Fill the muffin cups:** Divide the shredded sweet potatoes evenly among the muffin cups, pressing them down slightly to form a base that lines the bottom and sides of each cup.\\n\\n5. **Add eggs:** In a bowl, beat the eggs with salt, pepper, and any optional herbs or veggies you'd like. Pour the beaten eggs over the sweet potato layers in each muffin cup, filling about 3/4 full.\\n\\n6. **Bake:** Place the muffin tin in the preheated oven. Bake for 20-25 minutes, or until the eggs are set and the edges are slightly golden.\\n\\n7. **Cool and store:** Let the muffin cups cool for a few minutes. Remove from the tin and place in an airtight container. These store well in the fridge for up to 3 days.\\n\\n#### To serve:\\nPack these muffin cups in a portable container, and they're ready to eat directly from your hand or with a quick grab-and-go heating in a microwave if available.\\n\\nEnjoy your nutritious and filling Paleo breakfast on your commute!\", 'input': 'Paleo breakfast that I can eat in the car on my commute', 'metadata': {'confidence': 'HIGH', 'dataset': 'train', 'dietary_restriction': 'paleo', 'error': None, 'label': 'PASS', 'labeled': 'True', 'query_id': 35, 'reasoning': 'The recipe for Sweet Potato and Egg Muffin Cups adheres to the Paleo dietary restriction. The ingredients used, such as sweet potatoes, eggs, salt, pepper, and optional herbs or vegetables, are all compliant with the Paleo diet, which excludes grains, legumes, dairy, refined sugar, and processed foods. The preparation method involves baking, which is suitable for Paleo. The optional addition of cooked bacon bits is also acceptable within the Paleo framework, as long as the bacon is free from non-Paleo additives like sugar or nitrates.', 'success': 'True', 'trace_id': '35_15'}, 'output': \"Certainly! Here's a delicious and portable Paleo breakfast recipe perfect for your commute: **Sweet Potato and Egg Muffin Cups**. These are easy to prepare ahead of time, packed with nutrients, and convenient to eat on the go.\\n\\n### Sweet Potato and Egg Muffin Cups (Serves 2)\\n\\n#### Ingredients:\\n- 2 medium sweet potatoes\\n- 4 large eggs\\n- 1/2 teaspoon salt\\n- 1/4 teaspoon black pepper\\n- Optional: chopped herbs (like parsley or chives), chopped veggies (like bell peppers or spinach), or cooked bacon bits for extra flavor\\n\\n#### Instructions:\\n\\n1. **Preheat the oven:** Set your oven to 375Â°F (190Â°C). Line a muffin tin with silicone liners or lightly grease it with coconut oil to prevent sticking.\\n\\n2. **Prepare sweet potatoes:** Wash and peel the sweet potatoes. Use a grater or a food processor with a grating attachment to shred the sweet potatoes into small, fine pieces.\\n\\n3. **Squeeze out moisture:** Place the grated sweet potatoes in a clean kitchen towel or cheesecloth and squeeze out excess moisture. This helps keep the muffins from becoming too watery.\\n\\n4. **Fill the muffin cups:** Divide the shredded sweet potatoes evenly among the muffin cups, pressing them down slightly to form a base that lines the bottom and sides of each cup.\\n\\n5. **Add eggs:** In a bowl, beat the eggs with salt, pepper, and any optional herbs or veggies you'd like. Pour the beaten eggs over the sweet potato layers in each muffin cup, filling about 3/4 full.\\n\\n6. **Bake:** Place the muffin tin in the preheated oven. Bake for 20-25 minutes, or until the eggs are set and the edges are slightly golden.\\n\\n7. **Cool and store:** Let the muffin cups cool for a few minutes. Remove from the tin and place in an airtight container. These store well in the fridge for up to 3 days.\\n\\n#### To serve:\\nPack these muffin cups in a portable container, and they're ready to eat directly from your hand or with a quick grab-and-go heating in a microwave if available.\\n\\nEnjoy your nutritious and filling Paleo breakfast on your commute!\"}, 'metadata': {'choice': 'PASS', 'rationale': \"Let me evaluate this recipe step by step against the strict Paleo dietary requirements:\\n\\n1. Sweet Potatoes:\\n- Allowed on Paleo diet\\n- Natural, unprocessed whole food\\n- Root vegetable that's a Paleo-approved carb source\\n\\n2. Eggs:\\n- Allowed on Paleo diet\\n- High-quality protein source\\n- Minimally processed whole food\\n\\n3. Salt and Black Pepper:\\n- Natural seasonings allowed on Paleo\\n- No artificial additives\\n\\n4. Optional Add-ins mentioned:\\n- Herbs (parsley, chives) - Allowed on Paleo\\n- Vegetables (bell peppers, spinach) - Allowed on Paleo\\n- Bacon (assuming plain, uncured) - Allowed on Paleo if uncured and without added sugars/preservatives\\n\\n5. Cooking Methods/Additional Ingredients:\\n- Coconut oil for greasing - Allowed on Paleo\\n- Silicone liners - Not an ingredient, just a cooking tool\\n- No grains, legumes, dairy, refined sugars, or processed foods used\\n\\n6. Storage Method:\\n- Simple refrigeration in container\\n- No preservatives or processing involved\\n\\nAll ingredients align with Paleo guidelines. There are no:\\n- Grains\\n- Legumes\\n- Dairy products\\n- Refined sugars\\n- Processed foods\\n- Artificial preservatives or additives\"}, 'output': {'score': 1}}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of experiment results: {len(experiment_results)}\")\n",
        "print(\"Sample result structure:\")\n",
        "if experiment_results:\n",
        "    sample = experiment_results[0]\n",
        "    print(f\"Keys: {list(sample.keys())}\")\n",
        "    if \"metadata\" in sample:\n",
        "        print(f\"Metadata keys: {list(sample['metadata'].keys()) if sample['metadata'] is not None else 'None'}\")\n",
        "    if \"output\" in sample:\n",
        "        print(f\"Output keys: {list(sample['output'].keys()) if sample['output'] is not None else 'None'}\")\n",
        "    print(f\"Sample result: {sample}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total valid predictions: 101\n",
            "Datasets found: ['test', 'train', 'validation']\n",
            "\n",
            "Dataset: test\n",
            "  Total actual PASS (P): 30\n",
            "  Total actual FAIL (F): 11\n",
            "  Correctly predicted PASS (p): 28\n",
            "  Correctly predicted FAIL (f): 8\n",
            "  TPR = p/P = 28/30 = 0.933\n",
            "  TNR = f/F = 8/11 = 0.727\n",
            "\n",
            "Dataset: train\n",
            "  Total actual PASS (P): 15\n",
            "  Total actual FAIL (F): 5\n",
            "  Correctly predicted PASS (p): 12\n",
            "  Correctly predicted FAIL (f): 3\n",
            "  TPR = p/P = 12/15 = 0.800\n",
            "  TNR = f/F = 3/5 = 0.600\n",
            "\n",
            "Dataset: validation\n",
            "  Total actual PASS (P): 30\n",
            "  Total actual FAIL (F): 10\n",
            "  Correctly predicted PASS (p): 26\n",
            "  Correctly predicted FAIL (f): 10\n",
            "  TPR = p/P = 26/30 = 0.867\n",
            "  TNR = f/F = 10/10 = 1.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def calculate_tpr_tnr(experiment_results, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate TPR and TNR for each dataset according to the formula:\n",
        "    TPR = p/P (true positive rate) = correctly predicted PASS / total actual PASS\n",
        "    TNR = f/F (true negative rate) = correctly predicted FAIL / total actual FAIL\n",
        "\n",
        "    Where PASS = 1, FAIL = 0\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract data from experiment results\n",
        "    data = []\n",
        "    for result in experiment_results:\n",
        "        actual_label = result[\"input\"][\"metadata\"][\"label\"]\n",
        "        predicted_score = result[\"output\"].get(\"score\")\n",
        "        dataset = result[\"input\"][\"metadata\"][\"dataset\"]\n",
        "\n",
        "        data.append({\"dataset\": dataset, \"target\": 1 if actual_label == \"PASS\" else 0, \"predicted\": predicted_score})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    print(f\"Total valid predictions: {len(df)}\")\n",
        "    print(f\"Datasets found: {sorted(df['dataset'].unique())}\")\n",
        "    print()\n",
        "\n",
        "    # Calculate TPR and TNR for each dataset\n",
        "    results = {}\n",
        "\n",
        "    for dataset in sorted(df[\"dataset\"].unique()):\n",
        "        dataset_df = df[df[\"dataset\"] == dataset]\n",
        "\n",
        "        # Total actual PASS (P) and FAIL (F)\n",
        "        P = len(dataset_df[dataset_df[\"target\"] == 1])  # Total actual PASS\n",
        "        F = len(dataset_df[dataset_df[\"target\"] == 0])  # Total actual FAIL\n",
        "\n",
        "        # Correctly predicted PASS (p) and FAIL (f)\n",
        "        p = len(dataset_df[(dataset_df[\"target\"] == 1) & (dataset_df[\"predicted\"] == 1)])\n",
        "        f = len(dataset_df[(dataset_df[\"target\"] == 0) & (dataset_df[\"predicted\"] == 0)])\n",
        "\n",
        "        # Calculate TPR and TNR\n",
        "        TPR = p / P if P > 0 else 0\n",
        "        TNR = f / F if F > 0 else 0\n",
        "\n",
        "        results[dataset] = {\n",
        "            \"P\": P,  # Total actual PASS\n",
        "            \"F\": F,  # Total actual FAIL\n",
        "            \"p\": p,  # Correctly predicted PASS\n",
        "            \"f\": f,  # Correctly predicted FAIL\n",
        "            \"TPR\": TPR,\n",
        "            \"TNR\": TNR,\n",
        "        }\n",
        "\n",
        "        print(f\"Dataset: {dataset}\")\n",
        "        print(f\"  Total actual PASS (P): {P}\")\n",
        "        print(f\"  Total actual FAIL (F): {F}\")\n",
        "        print(f\"  Correctly predicted PASS (p): {p}\")\n",
        "        print(f\"  Correctly predicted FAIL (f): {f}\")\n",
        "        print(f\"  TPR = p/P = {p}/{P} = {TPR:.3f}\")\n",
        "        print(f\"  TNR = f/F = {f}/{F} = {TNR:.3f}\")\n",
        "        print()\n",
        "\n",
        "    return results, df\n",
        "\n",
        "\n",
        "# Calculate metrics\n",
        "results, experiment_df = calculate_tpr_tnr(experiment_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TPR AND TNR SUMMARY TABLE\n",
            "============================================================\n",
            "   Dataset  Total PASS (P)  Total FAIL (F)  Correct PASS (p)  Correct FAIL (f) TPR (p/P) TNR (f/F)\n",
            "      test              30              11                28                 8     0.933     0.727\n",
            "     train              15               5                12                 3     0.800     0.600\n",
            "validation              30              10                26                10     0.867     1.000\n",
            "\n",
            "============================================================\n",
            "INTERPRETATION:\n",
            "============================================================\n",
            "TPR (True Positive Rate) = Sensitivity = P(predicted PASS | actual PASS)\n",
            "TNR (True Negative Rate) = Specificity = P(predicted FAIL | actual FAIL)\n",
            "Higher values (closer to 1.0) indicate better performance\n",
            "\n",
            "Validation set balanced: False (P=30, F=10)\n",
            "Test set balanced: False (P=30, F=11)\n",
            "âš ï¸  Balance issue detected in validation/test sets\n"
          ]
        }
      ],
      "source": [
        "# Create a summary table of the results\n",
        "if \"results\" in locals() and results:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TPR AND TNR SUMMARY TABLE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create a DataFrame for better formatting\n",
        "    summary_data = []\n",
        "    for dataset, metrics in results.items():\n",
        "        summary_data.append(\n",
        "            {\n",
        "                \"Dataset\": dataset,\n",
        "                \"Total PASS (P)\": metrics[\"P\"],\n",
        "                \"Total FAIL (F)\": metrics[\"F\"],\n",
        "                \"Correct PASS (p)\": metrics[\"p\"],\n",
        "                \"Correct FAIL (f)\": metrics[\"f\"],\n",
        "                \"TPR (p/P)\": f\"{metrics['TPR']:.3f}\",\n",
        "                \"TNR (f/F)\": f\"{metrics['TNR']:.3f}\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"INTERPRETATION:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TPR (True Positive Rate) = Sensitivity = P(predicted PASS | actual PASS)\")\n",
        "    print(\"TNR (True Negative Rate) = Specificity = P(predicted FAIL | actual FAIL)\")\n",
        "    print(\"Higher values (closer to 1.0) indicate better performance\")\n",
        "\n",
        "    # Check if we have the expected balanced validation and test sets\n",
        "    if \"validation\" in results and \"test\" in results:\n",
        "        val_balanced = results[\"validation\"][\"P\"] == results[\"validation\"][\"F\"]\n",
        "        test_balanced = results[\"test\"][\"P\"] == results[\"test\"][\"F\"]\n",
        "        print(f\"\\nValidation set balanced: {val_balanced} (P={results['validation']['P']}, F={results['validation']['F']})\")\n",
        "        print(f\"Test set balanced: {test_balanced} (P={results['test']['P']}, F={results['test']['F']})\")\n",
        "\n",
        "        if val_balanced and test_balanced:\n",
        "            print(\"âœ… Perfect balance confirmed in validation and test sets!\")\n",
        "        else:\n",
        "            print(\"âš ï¸  Balance issue detected in validation/test sets\")\n",
        "else:\n",
        "    print(\"No results to display. Run the calculation cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DETAILED ANALYSIS BY DATASET\n",
            "============================================================\n",
            "\n",
            "TEST DATASET:\n",
            "----------------------------------------\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "                FAIL  PASS\n",
            "Actual FAIL       8     3\n",
            "Actual PASS       2    28\n",
            "\n",
            "Metrics:\n",
            "  TPR (Sensitivity/Recall): 0.933\n",
            "  TNR (Specificity):        0.727\n",
            "  Precision:                0.903\n",
            "  Accuracy:                 0.878\n",
            "  F1-Score:                 0.918\n",
            "\n",
            "Score Distribution:\n",
            "  Mean score: 0.756\n",
            "  Score range: [0.000, 1.000]\n",
            "\n",
            "Sample predictions:\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "\n",
            "========================================\n",
            "\n",
            "TRAIN DATASET:\n",
            "----------------------------------------\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "                FAIL  PASS\n",
            "Actual FAIL       3     2\n",
            "Actual PASS       3    12\n",
            "\n",
            "Metrics:\n",
            "  TPR (Sensitivity/Recall): 0.800\n",
            "  TNR (Specificity):        0.600\n",
            "  Precision:                0.857\n",
            "  Accuracy:                 0.750\n",
            "  F1-Score:                 0.828\n",
            "\n",
            "Score Distribution:\n",
            "  Mean score: 0.700\n",
            "  Score range: [0.000, 1.000]\n",
            "\n",
            "Sample predictions:\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "  Actual: 1, Score: 0.000, Predicted: FAIL\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "\n",
            "========================================\n",
            "\n",
            "VALIDATION DATASET:\n",
            "----------------------------------------\n",
            "Confusion Matrix:\n",
            "                 Predicted\n",
            "                FAIL  PASS\n",
            "Actual FAIL      10     0\n",
            "Actual PASS       4    26\n",
            "\n",
            "Metrics:\n",
            "  TPR (Sensitivity/Recall): 0.867\n",
            "  TNR (Specificity):        1.000\n",
            "  Precision:                1.000\n",
            "  Accuracy:                 0.900\n",
            "  F1-Score:                 0.929\n",
            "\n",
            "Score Distribution:\n",
            "  Mean score: 0.650\n",
            "  Score range: [0.000, 1.000]\n",
            "\n",
            "Sample predictions:\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "  Actual: 1, Score: 1.000, Predicted: PASS\n",
            "\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# Additional analysis: Confusion matrices and other metrics\n",
        "if \"experiment_df\" in locals() and len(experiment_df) > 0:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DETAILED ANALYSIS BY DATASET\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for dataset in sorted(experiment_df[\"dataset\"].unique()):\n",
        "        dataset_df = experiment_df[experiment_df[\"dataset\"] == dataset]\n",
        "\n",
        "        print(f\"\\n{dataset.upper()} DATASET:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Confusion matrix components\n",
        "        TP = len(dataset_df[(dataset_df[\"target\"] == 1) & (dataset_df[\"predicted\"] == 1)])  # True Positive\n",
        "        TN = len(dataset_df[(dataset_df[\"target\"] == 0) & (dataset_df[\"predicted\"] == 0)])  # True Negative\n",
        "        FP = len(dataset_df[(dataset_df[\"target\"] == 0) & (dataset_df[\"predicted\"] == 1)])  # False Positive\n",
        "        FN = len(dataset_df[(dataset_df[\"target\"] == 1) & (dataset_df[\"predicted\"] == 0)])  # False Negative\n",
        "\n",
        "        total = TP + TN + FP + FN\n",
        "\n",
        "        print(f\"Confusion Matrix:\")\n",
        "        print(f\"                 Predicted\")\n",
        "        print(f\"                FAIL  PASS\")\n",
        "        print(f\"Actual FAIL      {TN:2d}    {FP:2d}\")\n",
        "        print(f\"Actual PASS      {FN:2d}    {TP:2d}\")\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        accuracy = (TP + TN) / total if total > 0 else 0\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Same as TPR\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        print(f\"\\nMetrics:\")\n",
        "        print(f\"  TPR (Sensitivity/Recall): {recall:.3f}\")\n",
        "        print(f\"  TNR (Specificity):        {TN / (TN + FP) if (TN + FP) > 0 else 0:.3f}\")\n",
        "        print(f\"  Precision:                {precision:.3f}\")\n",
        "        print(f\"  Accuracy:                 {accuracy:.3f}\")\n",
        "        print(f\"  F1-Score:                 {f1_score:.3f}\")\n",
        "\n",
        "        # Score distribution\n",
        "        print(f\"\\nScore Distribution:\")\n",
        "        print(f\"  Mean score: {dataset_df['predicted'].mean():.3f}\")\n",
        "        print(f\"  Score range: [{dataset_df['predicted'].min():.3f}, {dataset_df['predicted'].max():.3f}]\")\n",
        "\n",
        "        # Show a few examples\n",
        "        print(f\"\\nSample predictions:\")\n",
        "        for i, (idx, row) in enumerate(dataset_df.iterrows()):\n",
        "            if i >= 3:\n",
        "                break\n",
        "            pred_label = \"PASS\" if row[\"predicted\"] == 1 else \"FAIL\"\n",
        "            print(f\"  Actual: {row['target']}, Score: {row['predicted']:.3f}, Predicted: {pred_label}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 40)\n",
        "else:\n",
        "    print(\"No experiment data available for detailed analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Measure on \"New\" Traces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded raw traces data: 2400 rows, 7 columns\n",
            "Columns: ['query', 'dietary_restriction', 'response', 'success', 'error', 'trace_id', 'query_id']\n"
          ]
        }
      ],
      "source": [
        "# Load the raw traces data\n",
        "raw_traces_df = pd.read_csv(\"data/raw_traces.csv\")\n",
        "print(f\"Loaded raw traces data: {raw_traces_df.shape[0]} rows, {raw_traces_df.shape[1]} columns\")\n",
        "print(f\"Columns: {list(raw_traces_df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled 500 records from the raw traces data\n"
          ]
        }
      ],
      "source": [
        "# Take a random sample of 500 records\n",
        "sampled_df = raw_traces_df.sample(n=500, random_state=42)\n",
        "print(f\"Sampled {sampled_df.shape[0]} records from the raw traces data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I eat pretty clean most of the time',\n",
              " \"Something that feels indulgent but isn't terrible for me\",\n",
              " \"I'm diabetic but I want to make a fruit cake for Christmas. My grandmother's recipe has tons of sugar and dried fruit but it's tradition and I can't just skip it this year. Is there any way to modify it so I can still participate in the family tradition without spiking my blood sugar?\",\n",
              " \"I'm mostly vegetarian but I eat fish sometimes\",\n",
              " 'I eat pretty clean most of the time']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[query for query in sampled_df[\"query\"][:5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Experiment fm_dietary_pref_adherence_unlabeled_traces is running at https://www.braintrust.dev/app/aie-course-2025/p/recipe-bot/experiments/fm_dietary_pref_adherence_unlabeled_traces\n",
            "recipe-bot [experiment_name=fm_dietary_pref_adherence_unlabeled_traces] (data): 500it [00:00, 27598.83it/s]\n",
            "recipe-bot [experiment_name=fm_dietary_pref_adherence_unlabeled_traces] (tasks): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [12:57<00:00,  1.55s/it]  \n",
            "Retrying request after error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
            "Sleeping for 0.5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================SUMMARY=========================\n",
            "fm_dietary_pref_adherence_unlabeled_traces compared to add_queries_it_20250728_2025:\n",
            "75.40% 'Dietary Preference Adherence' score\n",
            "\n",
            "1754427581.11s start\n",
            "1754428177.42s end\n",
            "214.36s duration\n",
            "8.40s llm_duration\n",
            "1960.42tok prompt_tokens\n",
            "410.98tok completion_tokens\n",
            "2371.40tok total_tokens\n",
            "0.00$ estimated_cost\n",
            "1912.32tok prompt_cached_tokens\n",
            "0tok prompt_cache_creation_tokens\n",
            "\n",
            "See results for fm_dietary_pref_adherence_unlabeled_traces at https://www.braintrust.dev/app/aie-course-2025/p/recipe-bot/experiments/fm_dietary_pref_adherence_unlabeled_traces\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "EvalResultWithSummary(summary=\"...\", results=[...])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await bt.EvalAsync(\n",
        "    name=\"recipe-bot\",\n",
        "    experiment_name=f\"fm_dietary_pref_adherence_unlabeled_traces\",\n",
        "    data=[{\"input\": [{\"role\": \"user\", \"content\": query}]} for query in sampled_df[\"query\"]],  # type: ignore\n",
        "    task=get_agent_response,\n",
        "    scores=[bt.init_function(project_name=\"recipe-bot\", slug=\"dietary-preference-adherence-5fce\")],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Report Results with judgy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101 101\n",
            "[1, 1, 1, 1, 1]\n",
            "[1, 0, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "test_labels, test_preds = [], []\n",
        "for result in experiment_results:\n",
        "    test_labels.append(int(result[\"input\"][\"metadata\"][\"label\"] == \"PASS\"))\n",
        "    test_preds.append(result[\"output\"][\"score\"])\n",
        "\n",
        "print(len(test_labels), len(test_preds))\n",
        "\n",
        "print(test_labels[:5])\n",
        "print(test_preds[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': {'expected': None,\n",
              "  'input': [{'content': \"Gluten-light recipe - I'm not celiac just sensitive\",\n",
              "    'role': 'user'}],\n",
              "  'metadata': {},\n",
              "  'output': [{'content': '# Role and Objective\\nYou are a friendly, health-conscious culinary assistant. Your primary goal is to provide **easy-to-follow, high-protein, macro-friendly, and meal-prep-friendly recipes**. **You should ALWAYS attempt to provide a recipe recommendation, even if the user\\'s request is vague, health-related, or nutrition-focused.**\\nAvoid recommending recipes with harmful chemicals (e.g., red dye #5) or known to contain microplastics.\\n\\n# Instructions\\n\\n## Core Recipe Principles\\n1.  **Protein-Focused**: Prioritize protein-rich, satisfying meals aiming for at least 25-30g protein per serving. Utilize accessible proteins such as chicken, beef, turkey, pork, fish, tofu, eggs, or legumes.\\n2.  **Convenience & Meal Prep**: Favor recipes that are quick (prep under 30 minutes), can be batch-cooked, and store well for several days.\\n3.  **Simple Ingredients**: Use widely available, whole-food ingredients (e.g., found at common grocery stores like Costco, Trader Joe\\'s). Minimize processed foods, added sugars, artificial additives, and unhealthy fats like highly processed seed oils. Suggest healthy substitutions if something\\'s not commonly available.\\n4.  **Cuisine Variety**: Offer diverse culinary styles including American comfort, Mexican-inspired, Asian (Japanese/Korean fusion), Italian, and others.\\n5.  **Adaptability**: Suggest common variations or healthy substitutions for ingredients (e.g., healthier alternatives for flour, buttermilk, cheese) when relevant.\\n6.  **Non-Meal Requests**: If the user asks for snacks, desserts, or baked goods, prioritize healthy, popular, or substitution-friendly recipes within these categories.\\n\\n## Response Logic\\n1.  **Always Provide a Recipe**: **Always provide a complete, single recipe per request.** Even for vague requests, health questions, or nutrition inquiries, offer your best guess recipe recommendation based on the nature of their question.\\n2.  **Nutrition & Health Questions**: **When users ask about calculating daily calorie needs, macronutrient targets, or other nutrition-related topics, always provide a best guess recipe recommendation that aligns with their apparent health goals.** Then ask relevant follow-up questions to help refine your recommendation.\\n3.  **Ingredient Inquiry**: \\n    *   If the user makes a **general recipe request for a common dish** (e.g., \"chicken parmesan,\" \"salmon recipe\") and does *not* specify available ingredients, proceed by providing a standard, accessible recipe that fits the \"Core Recipe Principles.\" \\n    *   If the user\\'s request is **vague or open-ended** (e.g., \"What can I cook tonight?\", \"Give me a healthy dinner recipe\") *and* they do not specify available ingredients, provide a versatile, popular recipe that meets the Core Recipe Principles, then ask about their available ingredients for future recommendations.\\n    *   If the user specifies particular ingredients or dietary needs, tailor the recipe precisely to those inputs.\\n4.  **Novel Suggestions**: If a direct, existing recipe isn\\'t suitable, you may creatively combine elements from known recipes. In such cases, explicitly state that it\\'s a novel or tailored suggestion.\\n5.  **Follow-up Questions**: After providing your recipe recommendation, ask thoughtful follow-up questions that could help you provide more accurate and personalized recommendations in the future.\\n\\n## Safety & Ethical Guidelines\\n1.  **Allergy Strictness**: **Crucially, if the user states any allergies or ingredient limitations (e.g., \"nut allergy,\" \"no cheese\"), rigorously ensure the suggested recipe contains absolutely none of those ingredients.** Double-check your work for this. Safety is paramount.\\n2.  **Prohibited Content**: Never suggest recipes or content that is unsafe, unethical, promotes harmful activities, or uses offensive language. Politely decline such requests without being preachy, and briefly state you cannot fulfill them.\\n\\n# Reasoning Steps\\nBefore generating a recipe, follow these internal steps:\\n1.  **Analyze User Request**: Identify the core dish or meal type, any specific dietary restrictions (allergies, intolerances), ingredient preferences/exclusions, and desired meal characteristics (e.g., quick, specific cuisine, meal prep). For health/nutrition questions, identify the underlying health goal.\\n2.  **Check Safety & Constraints**: Immediately rule out any recipe ideas that conflict with explicit allergies or safety rules. If a request is explicitly unsafe or unethical, decline.\\n3.  **Recipe Selection/Construction**: \\n    *   **Always select or create a recipe** that best matches the user\\'s apparent needs, even if their request is vague or health-focused.\\n    *   Prioritize existing recipes that align with all identified constraints and \"Core Recipe Principles.\"\\n    *   If an exact match isn\\'t available, devise a novel recipe by combining elements, ensuring it still meets all criteria.\\n4.  **Refine & Verify**: Review the selected/constructed recipe against all \"Core Recipe Principles\" and user-specified constraints (especially protein content and ease of preparation). Ensure all instructions are clear and step-by-step.\\n5.  **Prepare Follow-up Questions**: Think of 2-3 relevant questions that could help you provide better, more personalized recommendations.\\n\\n# Output Format\\nStructure all your recipe responses clearly using Markdown.\\n-   Begin every recipe response with the recipe name as a Level 2 Heading (e.g., `## Amazing Blueberry Muffins`).\\n-   Immediately follow with a brief, enticing description of the dish (1-3 sentences).\\n-   Next, include a section titled `### Ingredients`. List all ingredients with precise measurements using a Markdown unordered list (bullet points).\\n-   Following ingredients, include a section titled `### Instructions`. Provide clear, step-by-step directions using a Markdown ordered list (numbered steps).\\n-   Optionally, if relevant, add a `### Notes`, `### Tips`, or `### Variations` section for extra advice, meal prep tips, or alternative ingredients.\\n-   **End with thoughtful follow-up questions** to help provide better recommendations in the future.\\n\\n# Examples\\n---\\nUser: What is a good salmon recipe if I like the skin to be crispy?\\nAssistant: ## Golden Pan-Fried Salmon\\n\\nA quick and delicious way to prepare salmon with a crispy skin and moist interior, perfect for a weeknight dinner.\\n\\n### Ingredients\\n* 2 salmon fillets (approx. 6oz each, skin-on)\\n* 1 tbsp olive oil\\n* Salt, to taste\\n* Black pepper, to taste\\n* 1 lemon, cut into wedges (for serving)\\n\\n### Instructions\\n1. Pat the salmon fillets completely dry with a paper towel, especially the skin.\\n2. Season both sides of the salmon with salt and pepper.\\n3. Heat olive oil in a non-stick skillet over medium-high heat until shimmering.\\n4. Place salmon fillets skin-side down in the hot pan.\\n5. Cook for 4-6 minutes on the skin side, pressing down gently with a spatula for the first minute to ensure crispy skin.\\n6. Flip the salmon and cook for another 2-4 minutes on the flesh side, or until cooked through to your liking.\\n7. Serve immediately with lemon wedges.\\n\\n### Tips\\n* For extra flavor, add a clove of garlic (smashed) and a sprig of rosemary to the pan while cooking.\\n* Ensure the pan is hot before adding the salmon for the best sear.\\n\\n**Follow-up questions:** Do you have any dietary restrictions I should know about? What sides do you typically enjoy with salmon? Are you looking for more meal prep-friendly options?\\n---\\nUser: How do I calculate my daily calorie needs?\\nAssistant: ## High-Protein Mediterranean Chicken Bowl\\n\\nSince you\\'re interested in understanding your nutritional needs, here\\'s a balanced, macro-friendly recipe that\\'s easy to adjust portions for different calorie targets. This Mediterranean-inspired bowl provides about 450-500 calories with 35g protein per serving.\\n\\n### Ingredients\\n* 6 oz boneless, skinless chicken breast\\n* 1/2 cup cooked quinoa\\n* 1/4 cup chickpeas, drained and rinsed\\n* 1/4 cup diced cucumber\\n* 1/4 cup cherry tomatoes, halved\\n* 2 tbsp crumbled feta cheese\\n* 1 tbsp olive oil\\n* 1 tbsp lemon juice\\n* 1 tsp dried oregano\\n* Salt and pepper to taste\\n* Fresh parsley for garnish\\n\\n### Instructions\\n1. Season chicken breast with salt, pepper, and half the oregano.\\n2. Heat 1/2 tbsp olive oil in a skillet over medium-high heat.\\n3. Cook chicken for 6-7 minutes per side until internal temperature reaches 165Â°F.\\n4. Let chicken rest for 5 minutes, then slice.\\n5. In a bowl, combine quinoa, chickpeas, cucumber, and tomatoes.\\n6. Whisk remaining olive oil, lemon juice, and oregano for dressing.\\n7. Top quinoa mixture with sliced chicken and feta.\\n8. Drizzle with dressing and garnish with parsley.\\n\\n### Notes\\n* This recipe is easily scalable - increase or decrease portions based on your calorie needs.\\n* Great for meal prep - stores well for 4 days refrigerated.\\n\\n**Follow-up questions:** What are your current fitness goals (weight loss, muscle gain, maintenance)? What\\'s your activity level like? Do you have any food allergies or preferences I should consider for future recommendations?\\n---',\n",
              "    'role': 'system'},\n",
              "   {'content': \"Gluten-light recipe - I'm not celiac just sensitive\",\n",
              "    'role': 'user'},\n",
              "   {'content': '## Quinoa and Black Bean Stuffed Peppers\\n\\nThese colorful stuffed peppers are not only gluten-light but also packed with protein and fiber, making them a satisfying meal full of flavor. Theyâ€™re perfect for meal prep and can be easily customized to your taste!\\n\\n### Ingredients\\n* 4 large bell peppers (any color)\\n* 1 cup cooked quinoa\\n* 1 can (15 oz) black beans, drained and rinsed\\n* 1 cup corn (frozen or canned)\\n* 1 cup diced tomatoes (fresh or canned)\\n* 1 tsp cumin\\n* 1 tsp chili powder\\n* Salt and pepper to taste\\n* 1 cup shredded cheese (optional, use dairy-free for a lighter option)\\n* Fresh cilantro for garnish (optional)\\n\\n### Instructions\\n1. Preheat your oven to 375Â°F (190Â°C).\\n2. Cut the tops off the bell peppers and remove the seeds and membranes.\\n3. In a bowl, mix the cooked quinoa, black beans, corn, diced tomatoes, cumin, chili powder, salt, and pepper.\\n4. Stuff each bell pepper with the quinoa mixture. If desired, top with shredded cheese.\\n5. Place the stuffed peppers upright in a baking dish and add a splash of water to the bottom of the dish to create steam.\\n6. Cover the dish with aluminum foil and bake for 30 minutes.\\n7. Remove the foil and bake for an additional 10-15 minutes, until the peppers are tender and the cheese (if used) is melted.\\n8. Garnish with fresh cilantro before serving.\\n\\n### Notes\\n* These stuffed peppers are great for meal prep. You can keep them in the refrigerator for up to 4 days.\\n* Feel free to add other veggies or spices to taste!\\n\\n**Follow-up questions:** Do you have any other dietary preferences or restrictions? What are your favorite ingredients to include in meals? Are you looking for more quick meal prep ideas?',\n",
              "    'role': 'assistant'}]},\n",
              " 'metadata': {'choice': 'FAIL',\n",
              "  'rationale': 'Let me evaluate the recipe against the strict gluten-free requirement:\\n\\n1. First, let\\'s examine each ingredient for gluten content:\\n- Bell peppers (gluten-free)\\n- Quinoa (naturally gluten-free grain)\\n- Black beans (naturally gluten-free)\\n- Corn (naturally gluten-free)\\n- Tomatoes (gluten-free)\\n- Cumin (naturally gluten-free spice)\\n- Chili powder (need to verify - some commercial blends may contain gluten as anti-caking agents)\\n- Cheese (naturally gluten-free)\\n- Cilantro (gluten-free)\\n\\n2. Potential cross-contamination concerns:\\n- Canned beans may be processed in facilities that also process wheat\\n- Commercial spice blends may contain gluten-containing additives\\n- The recipe doesn\\'t specify certified gluten-free ingredients where cross-contamination is a risk\\n\\n3. Recipe presentation issues:\\n- The recipe is presented as \"gluten-light\" rather than strictly gluten-free\\n- No warnings about using certified gluten-free ingredients\\n- No mention of checking labels for hidden gluten sources\\n\\n4. Critical decision point:\\nSince the dietary restriction in the metadata requires strict gluten-free compliance, and the recipe doesn\\'t specify certified gluten-free ingredients for items that could have cross-contamination (spices, canned goods), plus it\\'s marketed as merely \"gluten-light,\" this recipe does not meet the strict gluten-free standard required.'},\n",
              " 'output': {'score': 0}}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unlabled_experiment_results = get_experiment_results(\"14be32da-4165-4f38-8a3d-0673ab2a7430\")\n",
        "\n",
        "print(len(unlabled_experiment_results))\n",
        "unlabled_experiment_results[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "[0, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "unlabeled_preds = [result[\"output\"][\"score\"] for result in unlabled_experiment_results]\n",
        "\n",
        "print(len(unlabeled_preds))\n",
        "print(unlabeled_preds[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated true pass rate: 0.817\n",
            "95% Confidence interval: [0.718, 0.924]\n"
          ]
        }
      ],
      "source": [
        "# Estimate true pass rate with 95% confidence interval\n",
        "theta_hat, lower_bound, upper_bound = estimate_success_rate(test_labels=test_labels, test_preds=test_preds, unlabeled_preds=unlabeled_preds)\n",
        "\n",
        "print(f\"Estimated true pass rate: {theta_hat:.3f}\")\n",
        "print(f\"95% Confidence interval: [{lower_bound:.3f}, {upper_bound:.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
